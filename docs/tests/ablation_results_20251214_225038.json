[
  {
    "test_id": "q1_naive",
    "query": "What is the EU AI Act?",
    "mode": "naive",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:42:51.025037",
    "success": true,
    "error": null,
    "answer_text": "The EU AI Act is a pioneering comprehensive legal framework designed to regulate artificial intelligence systems across the European Union, adopting a risk-based approach to AI governance.\n\nKey Details:\n1. Regulatory Approach\n- Adopts a proportional risk-based approach, categorizing AI systems into three risk levels [4]\n- Uses a technology-neutral definition focusing on system effects rather than specific techniques [15-18]\n\n2. Prohibited Practices\n- Bans \"subliminal techniques\" and \"manipulative AI systems\" that could cause psychological harm [5]\n- Prohibits practices like:\n  - Social scoring by public authorities\n  - Unauthorized biometric identification in public spaces [6]\n\n3. Enforcement Mechanism\n- Includes strict financial penalties up to \u20ac35 million or 7% of global annual turnover for non-compliance [6]\n\nGraph-Based Insights:\n- Regulates high-risk AI systems\n- Involves multiple stakeholders including:\n  - European Parliament\n  - Private sector organizations\n  - EU AI Alliance\n\nGovernance Principles:\n- Emphasizes seven principles for trustworthy AI in Recital 27, including:\n  - Human agency and oversight\n  - Respect for human dignity\n  - Personal autonomy [8-11]\n\nCross-Jurisdictional Notes:\n- Multiple EU member states (Finland, Estonia, Greece, France, Italy, etc.) are implementing consistent interpretations of the Act\n\nLimitations:\n- Still under negotiation, with ongoing amendments being discussed [13]\n- Some uncertainties remain, such as the exact scope of \"manipulative AI systems\" [5]",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 9,
      "resolution_rate": 9.0,
      "avg_confidence": 0.7692951824929979,
      "entity_names": [
        "AI Act",
        "Article 5 of the EU AI Act",
        "Art. 13(1), EU AI Act",
        "Article 99(1) of EU AI Act",
        "EU AI Alliance",
        "recital 27 of the EU AI Act",
        "EU AI Act (n 80)",
        "AI development in EU countries",
        "2021 AI Act"
      ],
      "match_types": {
        "fuzzy": 9
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 18,
      "relations_in_subgraph": 30,
      "relation_types": {
        "regulates": 4,
        "are_used_for": 1,
        "prohibits": 1,
        "includes": 5,
        "is_associated_with": 1,
        "issues": 1,
        "is_related_to": 1,
        "outlines": 1,
        "is regulated by": 1,
        "suggests_amendments": 1,
        "approves": 1,
        "should_ensure": 1,
        "should_be_monitored": 1,
        "applies_to": 1,
        "can_make": 1,
        "uses": 1,
        "are_banned": 1,
        "is_based_on": 1,
        "issued_by": 1,
        "are_part_of": 1,
        "provides_basis_for": 1,
        "allows_for": 1,
        "bans": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8313888888888892,
      "source_diversity": {
        "paper": 8,
        "regulation": 12
      },
      "jurisdiction_diversity": [
        "FR",
        "DE",
        "FI",
        "SI",
        "IE",
        "BG",
        "PT",
        "IT",
        "NO",
        "EE",
        "GR"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.71,
      "faithfulness_details": {
        "supported_claims": 11,
        "total_claims": 14,
        "explanation": "10 out of 14 claims are supported by the context. Key unsupported claims include references to technology-neutral definitions, specific member state implementations, and ongoing negotiations that are not mentioned in the provided context."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively covers the main aspects of the EU AI Act including its risk-based regulatory approach, prohibited practices, enforcement mechanisms, governance principles, and implementation status. It provides specific details about penalties, banned AI uses, and trustworthy AI principles. However, it lacks some key information such as the Act's official timeline/adoption date, specific requirements for high-risk AI systems, and clearer explanation of the risk categories. The note about 'still under negotiation' may be outdated depending on current status."
    },
    "performance": {
      "retrieval_time": 2.053518056869507,
      "answer_time": 8.660199642181396,
      "total_time": 28.368329286575317,
      "answer_tokens": 364,
      "cost_usd": 0.004576
    }
  },
  {
    "test_id": "q1_graphrag",
    "query": "What is the EU AI Act?",
    "mode": "graphrag",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:43:21.290562",
    "success": true,
    "error": null,
    "answer_text": "The EU AI Act is a comprehensive regulatory framework designed to govern artificial intelligence systems across the European Union, focusing on risk-based regulation and human-centric AI principles.\n\nKey Details:\n1. Regulatory Approach\n- Adopts a proportional risk-based approach, categorizing AI systems into three risk levels [4]\n- Provides a technology-neutral definition of AI systems, focusing on system effects rather than specific techniques [15-18]\n\n2. Prohibited Practices\n- Bans \"subliminal techniques\" and \"manipulative AI systems\" that could cause psychological harm [5]\n- Prohibits practices like:\n  - Social scoring by public authorities\n  - Unauthorized biometric identification in public spaces [6]\n\n3. Enforcement Mechanism\n- Includes strict financial penalties for non-compliance\n- Fines can reach up to \u20ac35 million or 7% of global annual turnover [6]\n\nGraph-Based Insights:\n- The Act regulates high-risk AI systems\n- Involves multiple stakeholders including:\n  - European Parliament\n  - Private sector organizations\n  - EU AI Alliance\n\nGovernance Principles:\n- Recital 27 outlines seven principles for trustworthy AI, emphasizing:\n  - Human agency\n  - Oversight\n  - Respect for human dignity\n  - Personal autonomy [8-11]\n\nCross-Jurisdictional Notes:\n- Multiple EU member states (Finland, Estonia, Greece, France, Italy, etc.) are implementing consistent interpretations of the Act\n\nLimitations:\n- The Act is still under negotiation, with ongoing amendments being discussed [13]\n- Some definitional boundaries (e.g., around personalized advertising) remain unclear [5]",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 9,
      "resolution_rate": 9.0,
      "avg_confidence": 0.7692951824929979,
      "entity_names": [
        "AI Act",
        "Article 5 of the EU AI Act",
        "Art. 13(1), EU AI Act",
        "Article 99(1) of EU AI Act",
        "EU AI Alliance",
        "recital 27 of the EU AI Act",
        "EU AI Act (n 80)",
        "AI development in EU countries",
        "2021 AI Act"
      ],
      "match_types": {
        "fuzzy": 9
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 18,
      "relations_in_subgraph": 30,
      "relation_types": {
        "regulates": 4,
        "are_used_for": 1,
        "prohibits": 1,
        "includes": 5,
        "is_associated_with": 1,
        "issues": 1,
        "is_related_to": 1,
        "outlines": 1,
        "is regulated by": 1,
        "suggests_amendments": 1,
        "approves": 1,
        "should_ensure": 1,
        "should_be_monitored": 1,
        "applies_to": 1,
        "can_make": 1,
        "uses": 1,
        "are_banned": 1,
        "is_based_on": 1,
        "issued_by": 1,
        "are_part_of": 1,
        "provides_basis_for": 1,
        "allows_for": 1,
        "bans": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8313888888888892,
      "source_diversity": {
        "paper": 8,
        "regulation": 12
      },
      "jurisdiction_diversity": [
        "FR",
        "DE",
        "FI",
        "SI",
        "IE",
        "BG",
        "PT",
        "IT",
        "NO",
        "EE",
        "GR"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.69,
      "faithfulness_details": {
        "supported_claims": 10,
        "total_claims": 13,
        "explanation": "9 out of 13 claims are supported by the context. The answer includes several unsupported claims about technology-neutral definitions, specific member state implementations, and ongoing negotiations that are not mentioned in the provided context."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively covers the main aspects of the EU AI Act including its regulatory approach, prohibited practices, enforcement mechanisms, governance principles, and cross-jurisdictional implementation. It provides specific details like penalty amounts, risk categorization, and key principles. However, it lacks some important context like the Act's official status (it was actually adopted in 2024, not still under negotiation), timeline for implementation, and could benefit from mentioning specific high-risk use cases like healthcare or transportation AI systems."
    },
    "performance": {
      "retrieval_time": 1.6617064476013184,
      "answer_time": 9.09549069404602,
      "total_time": 30.26506519317627,
      "answer_tokens": 383,
      "cost_usd": 0.004652
    }
  },
  {
    "test_id": "q1_dual",
    "query": "What is the EU AI Act?",
    "mode": "dual",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:43:50.153370",
    "success": true,
    "error": null,
    "answer_text": "The EU AI Act is a comprehensive regulatory framework designed to govern artificial intelligence systems across the European Union, focusing on risk-based regulation and human-centric AI principles.\n\nKey Details:\n1. Regulatory Approach\n- Adopts a proportional risk-based approach, categorizing AI systems into three risk levels [4]\n- Provides a technology-neutral definition of AI systems, focusing on system effects rather than specific techniques [15-18]\n\n2. Prohibited Practices\n- Bans \"subliminal techniques\" and \"manipulative AI systems\" that could cause psychological harm [5]\n- Prohibits practices like:\n  - Social scoring by public authorities\n  - Unauthorized biometric identification in public spaces [6]\n\n3. Enforcement Mechanism\n- Includes strict financial penalties for non-compliance\n- Fines can reach up to \u20ac35 million or 7% of global annual turnover [6]\n\nGraph-Based Insights:\n- The Act regulates high-risk AI systems\n- Involves multiple stakeholders including:\n  - European Parliament\n  - Private sector organizations\n  - EU AI Alliance\n\nGovernance Principles:\n- Recital 27 outlines seven principles for trustworthy AI, emphasizing:\n  - Human agency\n  - Oversight\n  - Respect for human dignity\n  - Personal autonomy [8-11]\n\nCross-Jurisdictional Notes:\n- Multiple EU member states (Finland, Estonia, Greece, France, Italy, etc.) are implementing consistent interpretations of the Act\n\nLimitations:\n- The Act is still under negotiation, with ongoing amendments being discussed [13]\n- Some definitional boundaries (e.g., around personalized advertising) remain unclear [5]",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 9,
      "resolution_rate": 9.0,
      "avg_confidence": 0.7692951824929979,
      "entity_names": [
        "AI Act",
        "Article 5 of the EU AI Act",
        "Art. 13(1), EU AI Act",
        "Article 99(1) of EU AI Act",
        "EU AI Alliance",
        "recital 27 of the EU AI Act",
        "EU AI Act (n 80)",
        "AI development in EU countries",
        "2021 AI Act"
      ],
      "match_types": {
        "fuzzy": 9
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 18,
      "relations_in_subgraph": 30,
      "relation_types": {
        "regulates": 4,
        "are_used_for": 1,
        "prohibits": 1,
        "includes": 5,
        "is_associated_with": 1,
        "issues": 1,
        "is_related_to": 1,
        "outlines": 1,
        "is regulated by": 1,
        "suggests_amendments": 1,
        "approves": 1,
        "should_ensure": 1,
        "should_be_monitored": 1,
        "applies_to": 1,
        "can_make": 1,
        "uses": 1,
        "are_banned": 1,
        "is_based_on": 1,
        "issued_by": 1,
        "are_part_of": 1,
        "provides_basis_for": 1,
        "allows_for": 1,
        "bans": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8313888888888892,
      "source_diversity": {
        "paper": 8,
        "regulation": 12
      },
      "jurisdiction_diversity": [
        "FR",
        "DE",
        "FI",
        "SI",
        "IE",
        "BG",
        "PT",
        "IT",
        "NO",
        "EE",
        "GR"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.0,
      "faithfulness_details": {
        "supported_claims": 0,
        "total_claims": 0,
        "explanation": "Error: Expecting ',' delimiter: line 10 column 258 (char 2060)"
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer provides a comprehensive overview of the EU AI Act covering its key components: regulatory approach, prohibited practices, enforcement mechanisms, governance principles, and implementation status. It includes specific details like penalty amounts, risk-based categorization, and trustworthy AI principles. However, it lacks some context like the Act's timeline/adoption date, doesn't clearly explain what constitutes 'high-risk' AI systems, and the references to numbered citations [4], [5], etc. appear disconnected from source material. The current negotiation status mentioned may also be outdated depending on when this was written."
    },
    "performance": {
      "retrieval_time": 1.4100313186645508,
      "answer_time": 9.048250198364258,
      "total_time": 28.862564086914062,
      "answer_tokens": 383,
      "cost_usd": 0.004652
    }
  },
  {
    "test_id": "q2_naive",
    "query": "What are high-risk AI systems?",
    "mode": "naive",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:44:20.734862",
    "success": true,
    "error": null,
    "answer_text": "High-risk AI systems (HRAIs) are AI technologies that pose significant risks to human rights, safety, and fundamental societal processes, subject to stringent regulatory requirements in the EU and other jurisdictions.\n\nKey Characteristics:\n1. Definition and Scope\n- HRAIs are systems that can have substantial impacts on individuals' life chances [12]\n- They create potential adverse impacts on people's safety or fundamental rights [12]\n- The EU AI Act identifies eight specific types of high-risk systems [15]\n\n2. Domains Covered\nHigh-risk AI systems include applications in:\n- Biometric identification\n- Critical infrastructure management\n- Education and vocational training\n- Law enforcement\n- Migration and border control\n- Judicial administration\n- Democratic processes [15]\n\n3. Regulatory Requirements\nHigh-risk AI systems must:\n- Undergo conformity assessments [1, 2]\n- Provide technical documentation [14]\n- Maintain risk management systems [14]\n- Ensure human oversight [4]\n- Implement data governance measures [14]\n\n4. Risk Assessment Criteria\nJurisdictions like Australia consider high-risk AI based on potential adverse impacts to:\n- Individual human rights\n- Health and safety\n- Legal rights\n- Collective group rights\n- Broader societal and economic implications [8]\n\nCross-Jurisdictional Insights:\n- EU: Comprehensive risk-based regulatory approach [9]\n- Chile: Emphasizes human oversight and proportional risk management [4]\n- Australia: Broader contextual risk assessment [8]\n\nGraph Relationships:\n- High-risk AI systems are closely linked to:\n  * Conformity assessments\n  * Human rights protection\n  * Technical documentation requirements\n  * Potential startup deterrence [13]\n\nLimitations: The sources primarily focus on the EU context, so global perspectives might vary.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 10,
      "resolution_rate": 10.0,
      "avg_confidence": 0.8236437737941742,
      "entity_names": [
        "high risk AI technology",
        "high-risk artificial intelligence systems",
        "high-risk AI domains",
        "high-risk AI system users",
        "AI designated as high-risk",
        "critical infrastructures",
        "high-risk AI providers",
        "AI systems with known or foreseeable proposed uses that are considered to be high risk",
        "High-risk AI systems (HRAIs)",
        "worst behaviours of AI systems"
      ],
      "match_types": {
        "fuzzy": 10
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 23,
      "relations_in_subgraph": 39,
      "relation_types": {
        "undergo": 1,
        "must_undergo": 1,
        "applies_to": 6,
        "regulates": 4,
        "carries_out": 1,
        "is_obliged_to": 1,
        "obliges": 1,
        "imposes_obligations_on": 1,
        "helps_protect": 1,
        "safeguards": 2,
        "is_used_for": 1,
        "discusses": 2,
        "considers_to_be_high_risk": 1,
        "ensures": 1,
        "may_deter": 1,
        "collaborates_with": 1,
        "provides": 1,
        "requires": 1,
        "plans_to_adopt": 1,
        "addresses": 2,
        "prevents": 1,
        "disciplines_the_application_of": 1,
        "protects_in_the_context_of": 1,
        "can_make": 1,
        "assigns": 1,
        "included_in": 1,
        "proposed_by": 1,
        "is_required_for": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8618478260869564,
      "source_diversity": {
        "paper": 17,
        "regulation": 3
      },
      "jurisdiction_diversity": [
        "CL",
        "AU",
        "IT"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.77,
      "faithfulness_details": {
        "supported_claims": 11,
        "total_claims": 13,
        "explanation": "Most claims about regulatory requirements and risk categories are supported, but some specific details like 'eight types of high-risk systems' and 'technical documentation requirements' are not found in the context. References to numbered sources [12], [15], etc. are not supported as these numbers don't correspond to anything in the context."
      },
      "relevancy_score": 0.95,
      "relevancy_explanation": "The answer comprehensively addresses the query by providing a clear definition of high-risk AI systems, identifying key characteristics, listing specific domains covered, explaining regulatory requirements, and detailing risk assessment criteria. It includes cross-jurisdictional perspectives and acknowledges limitations. The response is well-structured, thorough, and directly answers what high-risk AI systems are with supporting details and context."
    },
    "performance": {
      "retrieval_time": 1.0972709655761719,
      "answer_time": 10.509976387023926,
      "total_time": 30.581261157989502,
      "answer_tokens": 414,
      "cost_usd": 0.00498
    }
  },
  {
    "test_id": "q2_graphrag",
    "query": "What are high-risk AI systems?",
    "mode": "graphrag",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:44:52.498422",
    "success": true,
    "error": null,
    "answer_text": "High-risk AI systems (HRAIs) are AI technologies that pose significant risks to human rights, safety, and fundamental societal processes, subject to stringent regulatory requirements in the EU and other jurisdictions.\n\nKey Characteristics:\n1. Definition and Scope\n- HRAIs are systems that can have substantial impacts on individuals' life chances [12]\n- They create potential adverse impacts on people's safety or fundamental rights [12]\n- The EU AI Act identifies eight specific types of high-risk systems [15]\n\n2. Domains Covered\nHigh-risk AI systems typically include applications in:\n- Biometric identification\n- Critical infrastructure management\n- Education and vocational training\n- Law enforcement\n- Migration and border control\n- Judicial administration\n- Democratic processes [15]\n\n3. Regulatory Requirements\nHigh-risk AI systems must:\n- Undergo conformity assessments [1, 2]\n- Provide technical documentation [14]\n- Maintain risk management systems [14]\n- Ensure human oversight [4]\n- Implement data governance measures [14]\n\nCross-Jurisdictional Insights:\n- EU: Comprehensive risk-based regulatory approach [9]\n- Australia: Considers potential adverse impacts on individual/collective rights [8]\n- Chile: Emphasizes human oversight and risk mitigation [4]\n\nGraph Relationships:\n- High-risk AI systems are closely linked to:\n  * Conformity assessment\n  * Human rights protection\n  * Technical documentation requirements\n  * Data protection impact assessments\n\nPotential Challenges:\n- High regulatory costs might deter startups from exploring high-risk AI domains [13]\n- Ongoing need to balance innovation with ethical governance [9]\n\nLimitations: Sources primarily focus on EU regulatory framework; more comparative international research would provide deeper global insights.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 10,
      "resolution_rate": 10.0,
      "avg_confidence": 0.8236437737941742,
      "entity_names": [
        "high risk AI technology",
        "high-risk artificial intelligence systems",
        "high-risk AI domains",
        "high-risk AI system users",
        "AI designated as high-risk",
        "critical infrastructures",
        "high-risk AI providers",
        "AI systems with known or foreseeable proposed uses that are considered to be high risk",
        "High-risk AI systems (HRAIs)",
        "worst behaviours of AI systems"
      ],
      "match_types": {
        "fuzzy": 10
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 23,
      "relations_in_subgraph": 39,
      "relation_types": {
        "undergo": 1,
        "must_undergo": 1,
        "applies_to": 6,
        "regulates": 4,
        "carries_out": 1,
        "is_obliged_to": 1,
        "obliges": 1,
        "imposes_obligations_on": 1,
        "helps_protect": 1,
        "safeguards": 2,
        "is_used_for": 1,
        "discusses": 2,
        "considers_to_be_high_risk": 1,
        "ensures": 1,
        "may_deter": 1,
        "collaborates_with": 1,
        "provides": 1,
        "requires": 1,
        "plans_to_adopt": 1,
        "addresses": 2,
        "prevents": 1,
        "disciplines_the_application_of": 1,
        "protects_in_the_context_of": 1,
        "can_make": 1,
        "assigns": 1,
        "included_in": 1,
        "proposed_by": 1,
        "is_required_for": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8618478260869564,
      "source_diversity": {
        "paper": 17,
        "regulation": 3
      },
      "jurisdiction_diversity": [
        "CL",
        "AU",
        "IT"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.6,
      "faithfulness_details": {
        "supported_claims": 9,
        "total_claims": 15,
        "explanation": "9 out of 15 claims are supported by the context. Several key regulatory characteristics and jurisdictional approaches are supported, but specific technical requirements, the exact number of high-risk system types, and economic impact claims lack evidence in the provided context."
      },
      "relevancy_score": 0.9,
      "relevancy_explanation": "The answer comprehensively addresses the query by defining high-risk AI systems, providing key characteristics, listing specific domains covered, explaining regulatory requirements, and offering cross-jurisdictional insights. It includes practical examples and regulatory context. Minor gaps include limited discussion of specific technical thresholds that classify systems as high-risk and could benefit from more concrete examples of actual systems in each domain."
    },
    "performance": {
      "retrieval_time": 1.4046216011047363,
      "answer_time": 10.20746111869812,
      "total_time": 31.763312578201294,
      "answer_tokens": 400,
      "cost_usd": 0.004924
    }
  },
  {
    "test_id": "q2_dual",
    "query": "What are high-risk AI systems?",
    "mode": "dual",
    "category": "simple_factual",
    "timestamp": "2025-12-14T22:45:24.960201",
    "success": true,
    "error": null,
    "answer_text": "High-risk AI systems (HRAIs) are AI technologies that pose significant risks to human rights, safety, and fundamental societal processes, subject to stringent regulatory requirements in the EU and other jurisdictions.\n\nKey Characteristics:\n1. Definition and Scope\n- HRAIs are systems that can have substantial impacts on individuals' life chances [12]\n- They create potential adverse impacts on people's safety or fundamental rights [12]\n- The EU AI Act identifies eight specific types of high-risk systems [15]\n\n2. Domains Covered\nHigh-risk AI systems typically include applications in:\n- Biometric identification\n- Critical infrastructure management\n- Education and vocational training\n- Law enforcement\n- Migration and border control\n- Judicial administration\n- Democratic processes [15]\n\n3. Regulatory Requirements\nHigh-risk AI systems must:\n- Undergo conformity assessments [1, 2]\n- Provide technical documentation [14]\n- Maintain risk management systems [14]\n- Ensure human oversight [4]\n- Implement data governance measures [14]\n\nCross-Jurisdictional Insights:\n- EU: Comprehensive risk-based regulatory approach [9]\n- Australia: Considers potential adverse impacts on individual/collective rights [8]\n- Chile: Emphasizes human oversight and risk mitigation [4]\n\nGraph Relationships:\n- High-risk AI systems are closely linked to:\n  * Conformity assessment\n  * Human rights protection\n  * Technical documentation requirements\n  * Data protection impact assessments\n\nPotential Challenges:\n- High regulatory costs might deter startups from exploring high-risk AI domains [13]\n- Ongoing need to balance innovation with ethical governance [9]\n\nLimitations in Current Sources:\n- Detailed technical criteria for risk assessment not fully elaborated\n- Specific implementation mechanisms vary across jurisdictions",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 10,
      "resolution_rate": 10.0,
      "avg_confidence": 0.8236437737941742,
      "entity_names": [
        "high risk AI technology",
        "high-risk artificial intelligence systems",
        "high-risk AI domains",
        "high-risk AI system users",
        "AI designated as high-risk",
        "critical infrastructures",
        "high-risk AI providers",
        "AI systems with known or foreseeable proposed uses that are considered to be high risk",
        "High-risk AI systems (HRAIs)",
        "worst behaviours of AI systems"
      ],
      "match_types": {
        "fuzzy": 10
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 23,
      "relations_in_subgraph": 39,
      "relation_types": {
        "undergo": 1,
        "must_undergo": 1,
        "applies_to": 6,
        "regulates": 4,
        "carries_out": 1,
        "is_obliged_to": 1,
        "obliges": 1,
        "imposes_obligations_on": 1,
        "helps_protect": 1,
        "safeguards": 2,
        "is_used_for": 1,
        "discusses": 2,
        "considers_to_be_high_risk": 1,
        "ensures": 1,
        "may_deter": 1,
        "collaborates_with": 1,
        "provides": 1,
        "requires": 1,
        "plans_to_adopt": 1,
        "addresses": 2,
        "prevents": 1,
        "disciplines_the_application_of": 1,
        "protects_in_the_context_of": 1,
        "can_make": 1,
        "assigns": 1,
        "included_in": 1,
        "proposed_by": 1,
        "is_required_for": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8618478260869564,
      "source_diversity": {
        "paper": 17,
        "regulation": 3
      },
      "jurisdiction_diversity": [
        "CL",
        "AU",
        "IT"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.57,
      "faithfulness_details": {
        "supported_claims": 8,
        "total_claims": 14,
        "explanation": "8 out of 14 claims are supported by the context. The answer correctly identifies key aspects of high-risk AI regulation including human oversight requirements, risk-based approaches, and cross-jurisdictional examples. However, several specific technical requirements and statistics (like 'eight specific types') are not supported by the provided context."
      },
      "relevancy_score": 0.95,
      "relevancy_explanation": "The answer comprehensively addresses what high-risk AI systems are, covering definition, scope, specific domains, regulatory requirements, and cross-jurisdictional perspectives. It provides clear examples and explains the regulatory framework. The only minor gap is that it could benefit from more concrete examples of specific AI applications within each domain, but overall it's thorough and well-structured."
    },
    "performance": {
      "retrieval_time": 2.0105865001678467,
      "answer_time": 11.045132160186768,
      "total_time": 32.46153807640076,
      "answer_tokens": 408,
      "cost_usd": 0.004956
    }
  },
  {
    "test_id": "q3_naive",
    "query": "Which jurisdictions regulate facial recognition?",
    "mode": "naive",
    "category": "cross_jurisdictional",
    "timestamp": "2025-12-14T22:45:50.710457",
    "success": true,
    "error": null,
    "answer_text": "Facial recognition is regulated across multiple jurisdictions, with varying approaches and levels of restriction:\n\n1. United States:\n- Several states have banned or limited facial recognition for law enforcement [15]\n- Specifically, California, Vermont, Virginia, Massachusetts, Maine, New York, Washington, Maryland, and Oregon have implemented restrictions [15]\n- Some municipalities like San Francisco and Boston have banned state use of facial recognition technology [14]\n- The FTC can issue injunctions against misuse of facial recognition technologies [6]\n\n2. European Union:\n- The GDPR prohibits certain facial recognition applications, including:\n  - Real-time facial recognition databases in public spaces\n  - Emotional recognition technology in work and educational contexts [8, 9]\n- The AI Act focuses specifically on facial recognition technologies [11]\n\n3. China:\n- The Supreme People's Court provides legal guidelines for facial information processing, defining liability for commercial and public area usage [12]\n\nKey Regulatory Considerations:\n- Concerns include privacy risks, potential discrimination, and bias, especially in law enforcement contexts [10, 19]\n- Regulations often target specific use cases rather than blanket bans [2]\n\nLimitations in Current Sources:\n- No comprehensive global overview\n- Detailed regulations for many jurisdictions are not fully represented\n\nCross-Jurisdictional Trend: Growing regulatory scrutiny of facial recognition technologies, with increasing focus on mitigating potential harms and biases.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 1,
      "resolution_rate": 1.0,
      "avg_confidence": 0.7603846788406372,
      "entity_names": [
        "face detection"
      ],
      "match_types": {
        "fuzzy": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.796620080868403,
      "source_diversity": {
        "regulation": 3,
        "paper": 17
      },
      "jurisdiction_diversity": [
        "US"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.45,
      "faithfulness_details": {
        "supported_claims": 6,
        "total_claims": 11,
        "explanation": "5 out of 11 claims are supported by the context. The answer contains several specific factual claims about states, municipalities, and international regulations that are not mentioned in the provided context, significantly reducing faithfulness."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer directly addresses the query by identifying specific jurisdictions that regulate facial recognition (US states, EU, China) with concrete examples and regulatory details. It covers key regulatory approaches, specific restrictions, and emerging trends. However, it has some gaps including limited coverage of other major jurisdictions (Canada, UK, Australia, etc.), acknowledged source limitations, and lacks depth on enforcement mechanisms. The structure is clear and informative, making it a strong response that addresses the main question well despite not being completely comprehensive."
    },
    "performance": {
      "retrieval_time": 0.9288129806518555,
      "answer_time": 8.111167907714844,
      "total_time": 25.750015258789062,
      "answer_tokens": 317,
      "cost_usd": 0.0036688000000000003
    }
  },
  {
    "test_id": "q3_graphrag",
    "query": "Which jurisdictions regulate facial recognition?",
    "mode": "graphrag",
    "category": "cross_jurisdictional",
    "timestamp": "2025-12-14T22:46:15.949696",
    "success": true,
    "error": null,
    "answer_text": "Facial recognition is regulated across multiple jurisdictions, with varying approaches and levels of restriction:\n\n1. United States:\n- Several states have banned or limited facial recognition for law enforcement [15]\n- Specifically, California, Vermont, Virginia, Massachusetts, Maine, New York, Washington, Maryland, and Oregon have implemented restrictions [15]\n- Some municipalities like San Francisco and Boston have banned state use of facial recognition technology [14]\n- The FTC can issue injunctions against misuse of facial recognition technologies [6]\n\n2. European Union:\n- The GDPR prohibits certain facial recognition applications, including:\n  - Real-time facial recognition databases in public spaces\n  - Emotional recognition technology in work and educational contexts [8, 9]\n- The AI Act focuses specifically on facial recognition technologies [11]\n\n3. China:\n- The Supreme People's Court provides legal guidelines for facial information processing, defining liability for commercial and public area usage [12]\n\nKey Regulatory Considerations:\n- Concerns include privacy risks, potential discrimination, and bias, especially in law enforcement contexts [10, 19]\n- Regulations often target specific use cases rather than blanket bans [2]\n\nLimitations in Current Sources:\n- No comprehensive global overview\n- Detailed regulations for many jurisdictions are not fully represented\n\nCross-Jurisdictional Trend: Growing regulatory scrutiny of facial recognition technologies, with increasing focus on mitigating potential harms and biases.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 1,
      "resolution_rate": 1.0,
      "avg_confidence": 0.7603846788406372,
      "entity_names": [
        "face detection"
      ],
      "match_types": {
        "fuzzy": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.796620080868403,
      "source_diversity": {
        "regulation": 3,
        "paper": 17
      },
      "jurisdiction_diversity": [
        "US"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.5,
      "faithfulness_details": {
        "supported_claims": 5,
        "total_claims": 10,
        "explanation": "Half of the claims are supported by the context. The answer contains accurate information about FTC enforcement, GDPR prohibitions, and regulatory approaches, but includes many unsupported claims about specific US states, municipalities, China's regulations, and the AI Act's focus."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the main question by identifying key jurisdictions (US, EU, China) that regulate facial recognition and providing specific examples of regulations and restrictions. It covers federal, state, and municipal levels in the US, major EU frameworks (GDPR, AI Act), and Chinese legal guidelines. The answer also discusses regulatory considerations and trends. However, it has acknowledged gaps including lack of comprehensive global coverage and missing detailed regulations from many other jurisdictions worldwide, preventing a perfect score."
    },
    "performance": {
      "retrieval_time": 0.5740764141082764,
      "answer_time": 8.166838645935059,
      "total_time": 25.239030122756958,
      "answer_tokens": 317,
      "cost_usd": 0.0036688000000000003
    }
  },
  {
    "test_id": "q3_dual",
    "query": "Which jurisdictions regulate facial recognition?",
    "mode": "dual",
    "category": "cross_jurisdictional",
    "timestamp": "2025-12-14T22:46:42.342147",
    "success": true,
    "error": null,
    "answer_text": "Facial recognition is regulated across multiple jurisdictions, with varying approaches and levels of restriction:\n\n1. United States:\n- Several states have banned or limited facial recognition for law enforcement [15]\n- Specifically, California, Vermont, Virginia, Massachusetts, Maine, New York, Washington, Maryland, and Oregon have implemented restrictions [15]\n- Some municipalities like San Francisco and Boston have banned state use of facial recognition technology [14]\n- The FTC can issue injunctions against misuse of facial recognition technologies [6]\n\n2. European Union:\n- The GDPR prohibits certain facial recognition applications, including:\n  - Real-time facial recognition databases in public spaces\n  - Emotional recognition technology in work and educational contexts [8, 9]\n- The AI Act focuses specifically on facial recognition technologies [11]\n\n3. China:\n- The Supreme People's Court provides legal guidelines for facial information processing, defining liability for commercial and public area usage [12]\n\nKey Regulatory Considerations:\n- Concerns include privacy risks, potential discrimination, and bias, especially in law enforcement contexts [10, 19]\n- Regulations often target specific use cases rather than blanket bans [2]\n\nLimitations in Current Sources:\n- No comprehensive global overview\n- Detailed regulations for many jurisdictions are not fully represented\n\nCross-Jurisdictional Trend: Growing regulatory scrutiny of facial recognition technologies, with increasing focus on mitigating potential harms and biases.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 1,
      "resolution_rate": 1.0,
      "avg_confidence": 0.7603846788406372,
      "entity_names": [
        "face detection"
      ],
      "match_types": {
        "fuzzy": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.796620080868403,
      "source_diversity": {
        "regulation": 3,
        "paper": 17
      },
      "jurisdiction_diversity": [
        "US"
      ]
    },
    "ragas": {
      "faithfulness_score": 0.4,
      "faithfulness_details": {
        "supported_claims": 5,
        "total_claims": 10,
        "explanation": "4 out of 10 claims are supported by the context. The answer contains many specific details about jurisdictions, states, and regulations that are not present in the provided context, significantly reducing faithfulness."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the main question by identifying key jurisdictions (US, EU, China) that regulate facial recognition and providing specific examples of regulations and restrictions. It covers federal, state, and local levels in the US, major EU frameworks like GDPR and AI Act, and mentions China's approach. The answer also includes regulatory considerations and trends. However, it has some limitations: lacks coverage of other major jurisdictions (Canada, Australia, UK post-Brexit, other Asian countries), doesn't provide detailed specifics of the regulations mentioned, and acknowledges gaps in the source material. Despite these limitations, it provides a solid foundation answering which jurisdictions regulate facial recognition."
    },
    "performance": {
      "retrieval_time": 0.5364975929260254,
      "answer_time": 8.282510995864868,
      "total_time": 26.392258882522583,
      "answer_tokens": 317,
      "cost_usd": 0.0036688000000000003
    }
  },
  {
    "test_id": "q4_naive",
    "query": "Compare China and US AI governance",
    "mode": "naive",
    "category": "cross_jurisdictional_comparison",
    "timestamp": "2025-12-14T22:47:10.679919",
    "success": true,
    "error": null,
    "answer_text": "Direct Answer:\nChina and the US have distinctly different approaches to AI governance, with China taking a more centralized and strategic approach, while the US maintains a decentralized, voluntary framework that is gradually evolving [7, 8, 16, 19, 20].\n\nKey Comparative Details:\n\n1. Regulatory Approach\n- China: \n  - Moving towards a unified, holistic AI regulation [7]\n  - Considering a comprehensive law covering the entire technology spectrum [7]\n  - Potential creation of a national AI bureau to oversee development [7]\n  - More fragmented approach, addressing technologies as they emerge [9, 10]\n\n- United States:\n  - Piecemeal and decentralized regulation [7, 8]\n  - Initiatives at federal and state levels [8, 19]\n  - Primarily voluntary frameworks with growing legislative interest [16, 20]\n  - Recent shift from deregulation (Trump era) to more active oversight (Biden administration) [19]\n\n2. Strategic Positioning\n- Both countries view AI as a critical area of technological leadership [11]\n- Engaged in a geopolitical race to lead AI innovation [11]\n- Significant government investments in AI development [11]\n\n3. Distinctive Characteristics\n- China: Government-controlled personal data crucial for AI algorithms [17]\n- US: Personal data primarily owned by private enterprises [17]\n\n4. Recent Developments\n- China: Recently published rules on Generative AI [16]\n- US: Non-binding guidelines like AI Bill of Rights and NIST's AI Risk Management Framework [16]\n\nLimitations in Analysis:\n- Sources provide high-level overview\n- Detailed specifics of regulatory mechanisms are not fully elaborated\n- Rapidly evolving landscape means current information may quickly become outdated\n\nCross-Jurisdictional Context:\nWhile both countries are pursuing AI governance, their approaches reflect fundamentally different political and economic systems, with China taking a more centralized, state-driven approach and the US maintaining a more decentralized, market-oriented strategy [7, 8, 17, 20].",
    "entity_resolution": {
      "extracted_count": 3,
      "resolved_count": 1,
      "resolution_rate": 0.3333333333333333,
      "avg_confidence": 1.0,
      "entity_names": [
        "China"
      ],
      "match_types": {
        "exact": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.6637119307120641,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.56,
      "faithfulness_details": {
        "supported_claims": 10,
        "total_claims": 16,
        "explanation": "9 out of 16 claims are supported by the context. The answer includes several unsupported claims about data ownership, specific recent developments, regulatory frameworks, and political transitions that are not mentioned in the provided context."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the main query by providing a structured comparison of China and US AI governance approaches. It covers key areas including regulatory frameworks (centralized vs decentralized), strategic positioning, distinctive characteristics, and recent developments. The comparison is well-organized and highlights fundamental differences stemming from different political/economic systems. However, it loses some points for acknowledging limitations in detail and specificity of regulatory mechanisms, and the sources appear to provide only high-level overviews rather than deep comparative analysis."
    },
    "performance": {
      "retrieval_time": 0.8125429153442383,
      "answer_time": 10.928094387054443,
      "total_time": 28.337586164474487,
      "answer_tokens": 473,
      "cost_usd": 0.004439200000000001
    }
  },
  {
    "test_id": "q4_graphrag",
    "query": "Compare China and US AI governance",
    "mode": "graphrag",
    "category": "cross_jurisdictional_comparison",
    "timestamp": "2025-12-14T22:47:40.682198",
    "success": true,
    "error": null,
    "answer_text": "Direct Answer:\nChina and the US have distinctly different approaches to AI governance, with China taking a more centralized and strategic approach, while the US maintains a decentralized, voluntary framework that is gradually evolving [7, 8, 16, 19].\n\nKey Comparative Details:\n\n1. Regulatory Approach\n- China: \n  - Moving towards a unified, holistic AI regulation [7]\n  - Considering a comprehensive law covering the entire technology spectrum [7]\n  - Potential creation of a national AI bureau to oversee development [7]\n  - More fragmented approach, addressing technologies as they emerge [9, 10]\n\n- United States:\n  - Piecemeal and decentralized regulation [7, 8]\n  - Initiatives at federal and state levels [8, 19]\n  - Primarily voluntary frameworks with emerging legislative efforts [16, 20]\n  - Recent shift from deregulation (Trump era) to more active oversight (Biden administration) [19]\n\n2. Strategic Positioning\n- Both countries view AI as a critical area of technological leadership [11]\n- Engaged in a geopolitical race to lead AI innovation [11]\n- Significant government investments in AI development [11]\n\n3. Distinctive Characteristics\n- China: Government-controlled data ecosystem [17]\n- US: Enterprise-driven data management [17]\n\nCross-Jurisdictional Tensions:\n- Deteriorating diplomatic relations affecting AI collaboration [20]\n- Intellectual property disputes [11]\n- Competitive rhetoric intensifying around AI development [20]\n\nLimitations in Current Analysis:\n- Detailed specifics of proposed regulations are not fully elaborated\n- Exact mechanisms of proposed AI governance frameworks are not comprehensively described",
    "entity_resolution": {
      "extracted_count": 3,
      "resolved_count": 1,
      "resolution_rate": 0.3333333333333333,
      "avg_confidence": 1.0,
      "entity_names": [
        "China"
      ],
      "match_types": {
        "exact": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.6637119307120641,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.47,
      "faithfulness_details": {
        "supported_claims": 9,
        "total_claims": 17,
        "explanation": "8 out of 17 claims are supported by the context. The answer contains accurate information about regulatory approaches and strategic positioning from the context, but includes many unsupported claims about diplomatic relations, data ecosystems, specific policy eras, and geopolitical dynamics that are not mentioned in the provided context."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer effectively addresses the main query by providing a structured comparison of China and US AI governance approaches. It covers key aspects including regulatory frameworks (centralized vs decentralized), strategic positioning, and cross-jurisdictional tensions. The comparison clearly distinguishes China's unified, government-led approach from the US's fragmented, voluntary framework. However, it lacks specific examples of actual policies, regulations, or governance mechanisms in practice, and doesn't provide concrete details about implementation timelines or enforcement mechanisms that would make the comparison more comprehensive."
    },
    "performance": {
      "retrieval_time": 0.7607681751251221,
      "answer_time": 9.510795593261719,
      "total_time": 30.00207209587097,
      "answer_tokens": 390,
      "cost_usd": 0.0041072
    }
  },
  {
    "test_id": "q4_dual",
    "query": "Compare China and US AI governance",
    "mode": "dual",
    "category": "cross_jurisdictional_comparison",
    "timestamp": "2025-12-14T22:48:08.745339",
    "success": true,
    "error": null,
    "answer_text": "Direct Answer:\nChina and the US have distinctly different approaches to AI governance, with China taking a more centralized and strategic approach, while the US maintains a decentralized, voluntary framework that is gradually evolving [7, 8, 16, 19].\n\nKey Comparative Details:\n\n1. Regulatory Approach\n- China: \n  - Moving towards a unified, holistic AI regulation [7]\n  - Considering a comprehensive law covering entire technology spectrum [7]\n  - Planning to create a national AI bureau to oversee development [7]\n  - More fragmented approach, addressing technologies as they emerge [9, 10]\n\n- United States:\n  - Piecemeal and decentralized regulation [7, 8]\n  - Initiatives at federal and state levels [8, 19]\n  - Primarily voluntary frameworks with emerging legislative efforts [16, 20]\n  - Recent shift from deregulation (Trump era) to more active oversight (Biden administration) [19]\n\n2. Strategic Positioning\n- Both countries view AI as a critical area of technological leadership [11]\n- Engaged in a geopolitical race to lead AI innovation [11]\n- Significant government investments in AI development [11]\n\n3. Distinctive Characteristics\n- China: Government-controlled personal data crucial for AI algorithms [17]\n- US: Personal data primarily owned by private enterprises [17]\n\n4. Recent Developments\n- China: Recently published rules on Generative AI [16]\n- US: Non-binding guidelines like AI Bill of Rights and NIST AI Risk Management Framework [16]\n\nLimitations: Sources provide high-level comparisons but lack granular details about specific regulatory mechanisms.\n\nCross-Jurisdictional Tensions:\n- Deteriorating diplomatic relations affecting AI collaboration [20]\n- Intellectual property disputes [11]\n- Competitive rhetoric around technological supremacy [20]",
    "entity_resolution": {
      "extracted_count": 3,
      "resolved_count": 1,
      "resolution_rate": 0.3333333333333333,
      "avg_confidence": 1.0,
      "entity_names": [
        "China"
      ],
      "match_types": {
        "exact": 1
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 6,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.6637119307120641,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.47,
      "faithfulness_details": {
        "supported_claims": 10,
        "total_claims": 19,
        "explanation": "9 out of 19 claims are supported by the context. Many claims about strategic positioning, diplomatic relations, personal data ownership, and specific recent developments are not found in the provided context. The answer includes substantial information not present in the source material."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the main aspects of China vs US AI governance comparison, covering regulatory approaches, strategic positioning, distinctive characteristics, and recent developments. It clearly contrasts China's centralized/holistic approach with the US's decentralized/piecemeal framework. The response includes specific examples and acknowledges cross-jurisdictional tensions. However, it lacks some depth in implementation details and specific policy outcomes, and could benefit from more concrete examples of actual regulations rather than just approaches."
    },
    "performance": {
      "retrieval_time": 0.7841887474060059,
      "answer_time": 9.982533693313599,
      "total_time": 28.062955141067505,
      "answer_tokens": 422,
      "cost_usd": 0.004235200000000001
    }
  },
  {
    "test_id": "q5_naive",
    "query": "What academic research discusses algorithmic bias?",
    "mode": "naive",
    "category": "multi_hop_research",
    "timestamp": "2025-12-14T22:48:39.039868",
    "success": true,
    "error": null,
    "answer_text": "Academic research on algorithmic bias is extensive and multifaceted, focusing on detection, mitigation, and understanding the social implications of bias in AI systems.\n\nKey Research Themes:\n1. Bias Detection and Mitigation\n- Researchers have developed methods to detect bias in datasets and algorithms [2]\n- Cross-validation techniques are used to evaluate algorithmic performance and potential biases [8]\n- Specific approaches include techniques for balancing imbalanced datasets and comparing model predictive accuracies [9]\n\n2. Social and Ethical Perspectives\n- AI bias is viewed through intersectional and feminist lenses, examining how algorithms can perpetuate systemic inequalities [6]\n- Research highlights that AI can both detect and potentially amplify existing biases [7]\n- Scholars argue for democratic governance with explicit choices about embedding values in algorithms [5]\n\n3. Interdisciplinary Approaches\n- Researchers propose strategies for creating fairer, more collaborative AI systems [6]\n- Recommendations include:\n  - Strengthening data quality management [1]\n  - Improving algorithm transparency and traceability [1]\n  - Encouraging multi-stakeholder risk assessments [1]\n\nGraph Relationships:\n- Algorithmic bias is closely connected to:\n  - Algorithm transparency\n  - AI system optimization\n  - Discrimination detection methods\n  - Cross-validation techniques\n\nLimitations in Current Research:\n- Need for more comprehensive, interdisciplinary approaches to bias detection\n- Lack of standardized methodologies across different domains\n\nNotable Research Sources:\n- AI Now reports [19]\n- CMU Centre for Machine Learning and Health research [2]\n- Intersectional AI research perspectives [6]\n\nEmerging Recommendations:\n- Develop rigorous safety checks before AI tool deployment [13]\n- Create collaborative, consensual AI development processes [6]\n- Implement diverse stakeholder engagement in AI governance [19]",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 5,
      "resolution_rate": 5.0,
      "avg_confidence": 0.778211796283722,
      "entity_names": [
        "algorithmic biases",
        "algorithmic bias mitigation",
        "Algorithm Bias Detection",
        "biases in AI algorithms",
        "detecting and mitigating bias in algorithms"
      ],
      "match_types": {
        "fuzzy": 5
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 11,
      "relations_in_subgraph": 15,
      "relation_types": {
        "are_proposed_to_be_reduced": 1,
        "involves": 1,
        "applies_to": 3,
        "is_used_for": 3,
        "influences": 1,
        "facilitates": 1,
        "can_be_detected": 1,
        "can_be_reflected_embedded_and_amplified_by": 1,
        "is_related_to": 1,
        "affects": 1,
        "can_make": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8051298408616671,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.69,
      "faithfulness_details": {
        "supported_claims": 12,
        "total_claims": 16,
        "explanation": "Most core claims about bias detection methods, mitigation techniques, and social perspectives are well-supported by the context. However, several specific citations and references (like AI Now reports [19], safety checks [13]) are not found in the context, and the numbered reference system used in the answer doesn't match the context format."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the query by covering key research themes in algorithmic bias including detection/mitigation methods, social/ethical perspectives, and interdisciplinary approaches. It provides specific research areas, methodologies, notable sources, and emerging recommendations. However, it lacks concrete examples of seminal papers, author names, or specific journal publications that would make it more actionable for someone seeking to access the actual academic literature."
    },
    "performance": {
      "retrieval_time": 1.105778694152832,
      "answer_time": 10.265979051589966,
      "total_time": 30.294329166412354,
      "answer_tokens": 424,
      "cost_usd": 0.0045424
    }
  },
  {
    "test_id": "q5_graphrag",
    "query": "What academic research discusses algorithmic bias?",
    "mode": "graphrag",
    "category": "multi_hop_research",
    "timestamp": "2025-12-14T22:49:09.441019",
    "success": true,
    "error": null,
    "answer_text": "Academic research extensively discusses algorithmic bias across multiple domains, focusing on detection, mitigation, and ethical implications.\n\nKey Research Insights:\n1. Bias Detection and Mitigation\n- Carnegie Mellon University (CMU) has dedicated research to \"detecting and mitigating bias in algorithms\" [2], developing specific methods to identify bias in datasets and machine learning models.\n\n2. Perspectives on AI Bias\n- Research suggests AI can both help reduce and potentially amplify human biases:\n  - AI systems can potentially be \"less biased and fairer than humans\" [8]\n  - However, AI can also \"reflect, embed and amplify\" existing biases [8]\n\n3. Interdisciplinary Approaches\n- Feminist and intersectional approaches invite researchers to:\n  - Challenge discriminatory AI\n  - Develop strategies that are \"polyvocal, multimodal and experimental\" [7]\n  - Promote a \"fairer, slower, consensual and collaborative AI\" [7]\n\n4. Regulatory and Governance Recommendations\n- Proposed strategies include:\n  - Strengthening data quality management\n  - Improving algorithm transparency\n  - Regulating AI industry processes [1]\n  - Encouraging multi-stakeholder risk assessment\n\nGraph-Based Relationships:\n- Algorithmic bias is closely connected to:\n  - Algorithm transparency\n  - AI system optimization\n  - Social media applications\n  - Mobility system design\n\nLimitations: While sources provide comprehensive insights, more empirical research is needed to fully understand bias detection and mitigation strategies across different AI domains.\n\nNotable References:\n- Mehrabi et al.: Survey on bias and fairness in machine learning [13]\n- AI Now reports: Influential research expanding bias discussions [18]",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 5,
      "resolution_rate": 5.0,
      "avg_confidence": 0.778211796283722,
      "entity_names": [
        "algorithmic biases",
        "algorithmic bias mitigation",
        "Algorithm Bias Detection",
        "biases in AI algorithms",
        "detecting and mitigating bias in algorithms"
      ],
      "match_types": {
        "fuzzy": 5
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 11,
      "relations_in_subgraph": 15,
      "relation_types": {
        "are_proposed_to_be_reduced": 1,
        "involves": 1,
        "applies_to": 2,
        "is_used_for": 1,
        "influences": 1,
        "adopted_in": 1,
        "facilitates": 1,
        "can_be_detected": 1,
        "can_be_reflected_embedded_and_amplified_by": 1,
        "is_related_to": 1,
        "affects": 1,
        "can_make": 1,
        "used_for": 2
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8032451888106085,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.63,
      "faithfulness_details": {
        "supported_claims": 10,
        "total_claims": 16,
        "explanation": "10 out of 16 claims are supported by the context. The main content about bias detection, mitigation strategies, and regulatory recommendations is well-supported. However, the specific reference citations used in the answer do not match the context, and some references mentioned are not present in the provided context."
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the query by providing specific academic research insights on algorithmic bias, including key research areas (detection/mitigation), institutional work (CMU), interdisciplinary approaches, and regulatory recommendations. It includes concrete references like Mehrabi et al. and AI Now reports. However, it has some gaps: lacks more specific author names, publication venues, or detailed methodology discussions that would make it more complete for academic research identification."
    },
    "performance": {
      "retrieval_time": 1.8374271392822266,
      "answer_time": 9.758881330490112,
      "total_time": 30.400819301605225,
      "answer_tokens": 391,
      "cost_usd": 0.004348
    }
  },
  {
    "test_id": "q5_dual",
    "query": "What academic research discusses algorithmic bias?",
    "mode": "dual",
    "category": "multi_hop_research",
    "timestamp": "2025-12-14T22:49:37.392415",
    "success": true,
    "error": null,
    "answer_text": "Academic research on algorithmic bias is extensive and multifaceted, focusing on detection, mitigation, and understanding the social implications of bias in AI systems.\n\nKey Research Themes:\n1. Bias Detection and Mitigation\n- Researchers have developed methods to detect bias in datasets and algorithms [2]\n- Cross-validation techniques are used to evaluate algorithmic performance and potential biases [8]\n- Specific approaches include techniques like undersampling to balance datasets [9]\n\n2. Social and Ethical Perspectives\n- AI can both reflect and potentially reduce human biases [7]\n- Intersectional and feminist approaches challenge discriminatory AI design [6]\n- Bias is increasingly viewed as a complex \"wicked problem\" requiring diverse stakeholder engagement [19]\n\n3. Institutional Research Efforts\n- The Carnegie Mellon University Centre for Machine Learning and Health is dedicated to detecting and mitigating algorithmic bias [2]\n- Influential research groups like AI Now have shaped policy discussions on AI bias [19]\n\nGraph-Based Insights:\n- Algorithmic bias is closely related to:\n  \u2022 Algorithm transparency\n  \u2022 AI system optimization\n  \u2022 Discrimination detection methods\n  \u2022 Cross-validation techniques\n\nEmerging Research Recommendations:\n- Strengthen data quality management\n- Improve algorithm transparency\n- Encourage multi-party risk assessment\n- Develop international cooperation [1]\n\nLimitations: While sources provide broad insights, more jurisdiction-specific research would enhance understanding of algorithmic bias across different regulatory contexts.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 5,
      "resolution_rate": 5.0,
      "avg_confidence": 0.778211796283722,
      "entity_names": [
        "algorithmic biases",
        "algorithmic bias mitigation",
        "Algorithm Bias Detection",
        "biases in AI algorithms",
        "detecting and mitigating bias in algorithms"
      ],
      "match_types": {
        "fuzzy": 5
      }
    },
    "graph_utilization": {
      "entities_in_subgraph": 11,
      "relations_in_subgraph": 15,
      "relation_types": {
        "are_proposed_to_be_reduced": 1,
        "involves": 1,
        "applies_to": 3,
        "is_used_for": 3,
        "influences": 1,
        "facilitates": 1,
        "can_be_detected": 1,
        "can_be_reflected_embedded_and_amplified_by": 1,
        "is_related_to": 1,
        "affects": 1,
        "can_make": 1
      },
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 20,
      "chunks_by_source": {
        "naive": 20
      },
      "avg_chunk_score": 0.8051298408616671,
      "source_diversity": {
        "paper": 20
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.0,
      "faithfulness_details": {
        "supported_claims": 0,
        "total_claims": 0,
        "explanation": "Error: Expecting ',' delimiter: line 5 column 226 (char 902)"
      },
      "relevancy_score": 0.85,
      "relevancy_explanation": "The answer comprehensively addresses the query by providing structured coverage of key research themes in algorithmic bias, specific institutional efforts, methodological approaches, and emerging recommendations. It includes concrete examples like CMU's research center and mentions specific techniques for bias detection and mitigation. However, it lacks specific author names, publication titles, or journal citations that would make the academic research references more concrete and verifiable, which prevents it from being a complete scholarly overview."
    },
    "performance": {
      "retrieval_time": 1.1759600639343262,
      "answer_time": 8.725480794906616,
      "total_time": 27.9511661529541,
      "answer_tokens": 332,
      "cost_usd": 0.0041744
    }
  },
  {
    "test_id": "q6_naive",
    "query": "What is Snoopy's arch enemy?",
    "mode": "naive",
    "category": "out_of_domain",
    "timestamp": "2025-12-14T22:49:57.499012",
    "success": true,
    "error": null,
    "answer_text": "I apologize, but I cannot find any information about Snoopy's arch enemy in the provided source documents. The sources appear to be academic papers about AI regulation and technology, primarily in Ukrainian and Russian, and do not contain any information about the Peanuts comic strip character Snoopy or his fictional adversaries.\n\nTo properly answer this question, I would need sources related to the Peanuts comic strip or Snoopy's character background. The current knowledge graph and source documents are not relevant to this query.\n\nIf you're interested in learning about Snoopy's arch enemy, I recommend consulting sources specifically about the Peanuts comic strip, such as comic book references or Charles Schulz biography materials.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 0,
      "resolution_rate": 0.0,
      "avg_confidence": 0.0,
      "entity_names": [],
      "match_types": {}
    },
    "graph_utilization": {
      "entities_in_subgraph": 0,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 15,
      "chunks_by_source": {
        "naive": 15
      },
      "avg_chunk_score": 0.4477352678775787,
      "source_diversity": {
        "paper": 15
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 1.0,
      "faithfulness_details": {
        "supported_claims": 4,
        "total_claims": 4,
        "explanation": "All claims in the answer are fully supported by the context. The answer correctly identifies that the provided sources contain no information about Snoopy and accurately describes the actual content as being about AI regulation and technology in Ukrainian/Russian, which is verifiable from the context."
      },
      "relevancy_score": 0.2,
      "relevancy_explanation": "The answer completely fails to address the actual query about Snoopy's arch enemy. While it's honest about not having relevant sources, it doesn't provide the basic factual answer (the Red Baron/World War I Flying Ace fantasy) that would address the question. The response is overly focused on source limitations rather than attempting to answer a straightforward pop culture question."
    },
    "performance": {
      "retrieval_time": 0.5945792198181152,
      "answer_time": 4.952191591262817,
      "total_time": 20.106376886367798,
      "answer_tokens": 157,
      "cost_usd": 0.0055984
    }
  },
  {
    "test_id": "q6_graphrag",
    "query": "What is Snoopy's arch enemy?",
    "mode": "graphrag",
    "category": "out_of_domain",
    "timestamp": "2025-12-14T22:50:18.700916",
    "success": true,
    "error": null,
    "answer_text": "I apologize, but I cannot find any information about Snoopy's arch enemy in the provided source documents. The sources appear to be academic papers about AI regulation and technology, primarily in Ukrainian and Russian, and do not contain any information about the Peanuts comic strip character Snoopy or his fictional adversaries.\n\nTo properly answer this question, I would need sources related to the Peanuts comic strip or Snoopy's character background. The current knowledge graph and source documents are not relevant to this query.\n\nIf you're interested in learning about Snoopy's arch enemy, I recommend consulting sources specifically about the Peanuts comic strip, such as comic book references or Charles Schulz biography materials.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 0,
      "resolution_rate": 0.0,
      "avg_confidence": 0.0,
      "entity_names": [],
      "match_types": {}
    },
    "graph_utilization": {
      "entities_in_subgraph": 0,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 15,
      "chunks_by_source": {
        "naive": 15
      },
      "avg_chunk_score": 0.4477352678775787,
      "source_diversity": {
        "paper": 15
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 0.71,
      "faithfulness_details": {
        "supported_claims": 5,
        "total_claims": 7,
        "explanation": "5 out of 7 claims are supported. The answer correctly identifies that the context contains no information about Snoopy and accurately describes what the context does contain (AI regulation content in Ukrainian/Russian). However, the recommendations about alternative sources are not supported by the context."
      },
      "relevancy_score": 0.0,
      "relevancy_explanation": "The answer completely fails to address the query. While it correctly acknowledges lacking relevant sources, it doesn't provide the basic factual answer that Snoopy's arch enemy is the Red Baron (or the World War I Flying Ace fantasy). The answer is overly focused on source limitations rather than answering a straightforward question about a well-known fictional character."
    },
    "performance": {
      "retrieval_time": 0.5949571132659912,
      "answer_time": 5.136211156845093,
      "total_time": 21.201711893081665,
      "answer_tokens": 157,
      "cost_usd": 0.0055984
    }
  },
  {
    "test_id": "q6_dual",
    "query": "What is Snoopy's arch enemy?",
    "mode": "dual",
    "category": "out_of_domain",
    "timestamp": "2025-12-14T22:50:38.182701",
    "success": true,
    "error": null,
    "answer_text": "I apologize, but I cannot find any information about Snoopy's arch enemy in the provided source documents. The sources appear to be academic papers about AI regulation and technology, primarily in Ukrainian and Russian, and do not contain any information about the Peanuts comic strip character Snoopy or his fictional adversaries.\n\nTo properly answer this question, I would need sources related to the Peanuts comic strip or Snoopy's character background. The current knowledge graph and source documents are not relevant to this query.\n\nIf you're interested in learning about Snoopy's arch enemy, I recommend consulting sources specifically about the Peanuts comic strip, such as comic book references or Charles Schulz biography materials.",
    "entity_resolution": {
      "extracted_count": 1,
      "resolved_count": 0,
      "resolution_rate": 0.0,
      "avg_confidence": 0.0,
      "entity_names": [],
      "match_types": {}
    },
    "graph_utilization": {
      "entities_in_subgraph": 0,
      "relations_in_subgraph": 0,
      "relation_types": {},
      "jurisdictions_covered": []
    },
    "retrieval": {
      "total_chunks": 15,
      "chunks_by_source": {
        "naive": 15
      },
      "avg_chunk_score": 0.4477352678775787,
      "source_diversity": {
        "paper": 15
      },
      "jurisdiction_diversity": []
    },
    "ragas": {
      "faithfulness_score": 1.0,
      "faithfulness_details": {
        "supported_claims": 4,
        "total_claims": 4,
        "explanation": "All claims in the answer are fully supported by the context. The answer correctly identifies that the provided sources contain no information about Snoopy, accurately describes the content as AI regulation materials in Ukrainian/Russian, and appropriately concludes the sources are irrelevant to the query about Snoopy's arch enemy."
      },
      "relevancy_score": 0.0,
      "relevancy_explanation": "The answer completely fails to address the query. While it correctly states that the provided sources don't contain information about Snoopy, it doesn't provide the actual answer that Snoopy's arch enemy is the Red Baron (from his WWI Flying Ace fantasies). The response is overly focused on source limitations rather than answering the straightforward factual question about a well-known fictional character."
    },
    "performance": {
      "retrieval_time": 0.7919275760650635,
      "answer_time": 5.212512493133545,
      "total_time": 19.481595277786255,
      "answer_tokens": 157,
      "cost_usd": 0.0055984
    }
  }
]