# -*- coding: utf-8 -*-
"""
LaTeX exporter for ablation study results.

Generates:
1. ablation_table.tex - Main results table
2. ablation_vars.tex - \newcommand variables for inline citations
3. ablation_appendix.tex - Detailed I/O per query
4. ablation_data.tex - Data for pgfplots figures
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


def escape_latex(text: str) -> str:
    """Escape special LaTeX characters."""
    if not text:
        return ""
    replacements = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\textasciicircum{}',
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text


def truncate_text(text: str, max_len: int = 80) -> str:
    """Truncate text for display."""
    if len(text) <= max_len:
        return text
    return text[:max_len-3] + "..."


class LaTeXExporter:
    """Export ablation results to LaTeX format."""
    
    def __init__(self, results_json: Path):
        """Load results from JSON file."""
        with open(results_json) as f:
            self.results = json.load(f)
        
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Group by query
        self.by_query = {}
        for r in self.results:
            q = r['query']
            if q not in self.by_query:
                self.by_query[q] = {}
            self.by_query[q][r['mode']] = r
        
        # Group by mode
        self.by_mode = {'semantic': [], 'graph': [], 'dual': []}
        for r in self.results:
            self.by_mode[r['mode']].append(r)
    
    def compute_aggregates(self) -> Dict[str, Any]:
        """Compute aggregate statistics for variables."""
        agg = {}
        
        for mode in ['semantic', 'graph', 'dual']:
            results = self.by_mode[mode]
            if not results:
                continue
            
            # Faithfulness
            faith_scores = [r['ragas']['faithfulness_score'] for r in results]
            agg[f'faith_{mode}_mean'] = sum(faith_scores) / len(faith_scores)
            agg[f'faith_{mode}_max'] = max(faith_scores)
            agg[f'faith_{mode}_min'] = min(faith_scores)
            
            # Relevancy
            rel_scores = [r['ragas']['relevancy_score'] for r in results]
            agg[f'rel_{mode}_mean'] = sum(rel_scores) / len(rel_scores)
            
            # Resolution
            res_counts = [r['entity_resolution']['resolved_count'] for r in results]
            agg[f'res_{mode}_total'] = sum(res_counts)
            
            # Chunks by source
            s_total = sum(r['retrieval']['chunks_by_source'].get('semantic', 0) for r in results)
            r_total = sum(r['retrieval']['chunks_by_source'].get('graph_provenance', 0) for r in results)
            e_total = sum(r['retrieval']['chunks_by_source'].get('graph_entity', 0) for r in results)
            agg[f'chunks_{mode}_s'] = s_total
            agg[f'chunks_{mode}_r'] = r_total
            agg[f'chunks_{mode}_e'] = e_total
        
        # Winners by query
        winners = {'semantic': 0, 'graph': 0, 'dual': 0, 'tie': 0}
        for query, modes in self.by_query.items():
            scores = {m: modes[m]['ragas']['faithfulness_score'] for m in modes}
            max_score = max(scores.values())
            if max_score == 0:
                continue
            winner_modes = [m for m, s in scores.items() if s == max_score]
            if len(winner_modes) == 1:
                winners[winner_modes[0]] += 1
            else:
                winners['tie'] += 1
        
        agg['winners'] = winners
        agg['n_queries'] = len(self.by_query)
        agg['n_tests'] = len(self.results)
        
        return agg
    
    def generate_vars_tex(self) -> str:
        """Generate \newcommand variables for inline citations."""
        agg = self.compute_aggregates()
        
        lines = [
            "% Auto-generated by ablation_latex_export.py",
            f"% Generated: {datetime.now().isoformat()}",
            "%",
            "% Metric definitions: See Appendix \\ref{app:metrics} (metrics_glossary.tex)",
            "% - Faithfulness: Section \\ref{sec:metric-faithfulness}",
            "% - Relevancy: Section \\ref{sec:metric-relevancy}",
            "% - Resolution Rate: Section \\ref{sec:metric-resolution-rate}",
            "% - Entity Coverage: Section \\ref{sec:metric-entity-coverage}",
            "%",
            "",
            "% === AGGREGATE STATISTICS ===",
            f"\\newcommand{{\\nQueries}}{{{agg['n_queries']}}}",
            f"\\newcommand{{\\nTests}}{{{agg['n_tests']}}}",
            "",
            "% === FAITHFULNESS (\\ref{sec:metric-faithfulness}) ===",
        ]
        
        for mode in ['semantic', 'graph', 'dual']:
            m = mode[0].upper()  # S, G, D
            lines.append(f"\\newcommand{{\\faith{m}Mean}}{{{agg.get(f'faith_{mode}_mean', 0):.2f}}}")
            lines.append(f"\\newcommand{{\\faith{m}Max}}{{{agg.get(f'faith_{mode}_max', 0):.2f}}}")
            lines.append(f"\\newcommand{{\\faith{m}Min}}{{{agg.get(f'faith_{mode}_min', 0):.2f}}}")
        
        lines.extend([
            "",
            "% === RELEVANCY (\\ref{sec:metric-relevancy}) ===",
        ])
        
        for mode in ['semantic', 'graph', 'dual']:
            m = mode[0].upper()
            lines.append(f"\\newcommand{{\\rel{m}Mean}}{{{agg.get(f'rel_{mode}_mean', 0):.2f}}}")
        
        lines.extend([
            "",
            "% === WINNERS (\\ref{sec:metric-winner}) ===",
            f"\\newcommand{{\\winsSemantic}}{{{agg['winners']['semantic']}}}",
            f"\\newcommand{{\\winsGraph}}{{{agg['winners']['graph']}}}",
            f"\\newcommand{{\\winsDual}}{{{agg['winners']['dual']}}}",
            f"\\newcommand{{\\winsTie}}{{{agg['winners']['tie']}}}",
            "",
            "% === PER-QUERY VARIABLES ===",
        ])
        
        # Per-query faithfulness
        for i, (query, modes) in enumerate(self.by_query.items(), 1):
            for mode in ['semantic', 'graph', 'dual']:
                if mode in modes:
                    m = mode[0].upper()
                    faith = modes[mode]['ragas']['faithfulness_score']
                    lines.append(f"\\newcommand{{\\faithQ{i}{m}}}{{{faith:.2f}}}")
        
        return "\n".join(lines)
    
    def generate_table_tex(self) -> str:
        """Generate the main results table."""
        lines = [
            "% Auto-generated ablation results table",
            "\\begin{table}[htbp]",
            "\\centering",
            "\\caption{Ablation Results Across Retrieval Modes}",
            "\\label{tab:ablation_results}",
            "\\resizebox{\\linewidth}{!}{%",
            "\\begin{tabular}{clccccccccc}",
            "\\toprule",
            "\\# & Query & Mode & Faith. & Relev. & Res. & Subgraph & S/R/E & Sim. & E.Cov & P/R \\\\",
            "\\midrule",
        ]
        
        row_num = 1
        for query, modes in self.by_query.items():
            q_escaped = escape_latex(truncate_text(query, 40))
            
            for i, mode in enumerate(['semantic', 'graph', 'dual']):
                if mode not in modes:
                    continue
                
                r = modes[mode]
                
                # Find best faithfulness for this query
                all_faith = [modes[m]['ragas']['faithfulness_score'] for m in modes]
                best_faith = max(all_faith)
                faith = r['ragas']['faithfulness_score']
                faith_str = f"\\textbf{{{faith:.2f}}}" if faith == best_faith and faith > 0 else f"{faith:.2f}"
                
                # Metrics
                rel = r['ragas']['relevancy_score']
                res = r['entity_resolution']['resolved_count']
                ent = r['graph_utilization']['entities_in_subgraph']
                rels = r['graph_utilization']['relations_in_subgraph']
                
                chunks = r['retrieval']['chunks_by_source']
                s = chunks.get('semantic', 0)
                rc = chunks.get('graph_provenance', 0)
                e = chunks.get('graph_entity', 0)
                
                sim = r['retrieval'].get('avg_query_similarity', 0)
                sim_str = f"{sim:.2f}" if sim > 0 else "---"
                
                e_cov = r['coverage'].get('entity_coverage_rate', 0) * 100
                
                src_div = r['retrieval'].get('source_diversity', {})
                p = src_div.get('paper', 0)
                reg = src_div.get('regulation', 0)
                
                # Query column (only show on first mode)
                q_col = q_escaped if i == 0 else ""
                
                lines.append(
                    f"{row_num} & {q_col} & {mode} & {faith_str} & {rel:.2f} & {res} & "
                    f"{ent}/{rels} & {s}/{rc}/{e} & {sim_str} & {e_cov:.0f}\\% & {p}/{reg} \\\\"
                )
                row_num += 1
            
            lines.append("\\midrule")
        
        # Remove last midrule
        lines[-1] = "\\bottomrule"
        
        lines.extend([
            "\\end{tabular}%",
            "}",
            "\\smallskip",
            "\\begin{minipage}{\\linewidth}",
            "\\footnotesize",
            "\\textit{Columns:} Faith.\\ = Faithfulness (\\S\\ref{sec:metric-faithfulness}); "
            "Relev.\\ = Relevancy (\\S\\ref{sec:metric-relevancy}); "
            "Res.\\ = entities resolved (\\S\\ref{sec:metric-resolution-rate}); "
            "Subgraph = nodes/relations (\\S\\ref{sec:metric-subgraph}); "
            "S/R/E = chunks by source (\\S\\ref{sec:metric-sre}); "
            "Sim.\\ = avg query-chunk similarity (\\S\\ref{sec:metric-similarity}); "
            "E.Cov = entity coverage (\\S\\ref{sec:metric-entity-coverage}); "
            "P/R = paper/regulation sources (\\S\\ref{sec:metric-source-diversity}). "
            "\\textbf{Bold} = best per query.",
            "\\end{minipage}",
            "\\end{table}",
        ])
        
        return "\n".join(lines)
    
    def generate_appendix_tex(self) -> str:
        """Generate detailed I/O appendix for each query."""
        lines = [
            "% Auto-generated detailed ablation appendix",
            "\\chapter{Detailed Query Analysis}",
            "\\label{app:detailed_queries}",
            "",
        ]
        
        for i, (query, modes) in enumerate(self.by_query.items(), 1):
            q_escaped = escape_latex(query)
            
            # Get query metadata from first result
            first_result = list(modes.values())[0]
            category = first_result.get('category', 'unknown')
            
            lines.extend([
                f"\\section{{Query {i}: {q_escaped}}}",
                f"\\label{{sec:q{i}}}",
                "",
                f"\\textbf{{Category:}} {escape_latex(category)}",
                "",
                "\\begin{table}[htbp]",
                "\\centering",
                "\\caption{Metrics comparison for Query " + str(i) + " (see Appendix~\\ref{app:metrics} for definitions)}",
                "\\begin{tabular}{lccc}",
                "\\toprule",
                "Metric & Semantic & Graph & Dual \\\\",
                "\\midrule",
            ])
            
            # Metrics rows with section references
            metrics = [
                ('Faithfulness (\\S\\ref{sec:metric-faithfulness})', lambda r: f"{r['ragas']['faithfulness_score']:.2f}"),
                ('Relevancy (\\S\\ref{sec:metric-relevancy})', lambda r: f"{r['ragas']['relevancy_score']:.2f}"),
                ('Entities Resolved (\\S\\ref{sec:metric-resolution-rate})', lambda r: str(r['entity_resolution']['resolved_count'])),
                ('Subgraph Nodes (\\S\\ref{sec:metric-subgraph})', lambda r: str(r['graph_utilization']['entities_in_subgraph'])),
                ('Subgraph Relations', lambda r: str(r['graph_utilization']['relations_in_subgraph'])),
                ('Total Chunks', lambda r: str(r['retrieval']['total_chunks'])),
                ('Avg Similarity (\\S\\ref{sec:metric-similarity})', lambda r: f"{r['retrieval'].get('avg_query_similarity', 0):.2f}"),
                ('Entity Coverage (\\S\\ref{sec:metric-entity-coverage})', lambda r: f"{r['coverage'].get('entity_coverage_rate', 0)*100:.0f}\\%"),
            ]
            
            for metric_name, metric_fn in metrics:
                vals = []
                for mode in ['semantic', 'graph', 'dual']:
                    if mode in modes:
                        vals.append(metric_fn(modes[mode]))
                    else:
                        vals.append("---")
                lines.append(f"{metric_name} & {vals[0]} & {vals[1]} & {vals[2]} \\\\")
            
            lines.extend([
                "\\bottomrule",
                "\\end{tabular}",
                "\\end{table}",
                "",
            ])
            
            # Full answers
            lines.append("\\subsection*{Generated Answers}")
            
            for mode in ['semantic', 'graph', 'dual']:
                if mode not in modes:
                    continue
                
                r = modes[mode]
                answer = r.get('answer_text', 'No answer recorded')
                answer_escaped = escape_latex(answer)
                
                # Wrap long answers
                lines.extend([
                    f"\\textbf{{{mode.capitalize()} Mode:}}",
                    "\\begin{quote}",
                    f"\\small {answer_escaped}",
                    "\\end{quote}",
                    "",
                ])
            
            lines.append("\\clearpage")
            lines.append("")
        
        return "\n".join(lines)
    
    def generate_pgfplots_data(self) -> str:
        """Generate data file for pgfplots figures."""
        lines = [
            "% Data for pgfplots - faithfulness by mode and category",
            "% Format: category semantic graph dual",
        ]
        
        # Group by category
        by_category = {}
        for query, modes in self.by_query.items():
            cat = list(modes.values())[0].get('category', 'unknown')
            if cat not in by_category:
                by_category[cat] = {'semantic': [], 'graph': [], 'dual': []}
            for mode in ['semantic', 'graph', 'dual']:
                if mode in modes:
                    by_category[cat][mode].append(modes[mode]['ragas']['faithfulness_score'])
        
        lines.append("")
        lines.append("% === BAR CHART DATA ===")
        lines.append("% \\pgfplotstableread{")
        lines.append("category semantic graph dual")
        
        for cat, mode_scores in by_category.items():
            s_avg = sum(mode_scores['semantic']) / len(mode_scores['semantic']) if mode_scores['semantic'] else 0
            g_avg = sum(mode_scores['graph']) / len(mode_scores['graph']) if mode_scores['graph'] else 0
            d_avg = sum(mode_scores['dual']) / len(mode_scores['dual']) if mode_scores['dual'] else 0
            cat_clean = cat.replace('_', '-')
            lines.append(f"{cat_clean} {s_avg:.2f} {g_avg:.2f} {d_avg:.2f}")
        
        lines.append("% }\\datatable")
        
        # Scatter plot data
        lines.append("")
        lines.append("% === SCATTER PLOT DATA (resolution vs faithfulness) ===")
        lines.append("% mode resolution faithfulness")
        
        for r in self.results:
            mode = r['mode']
            res = r['entity_resolution']['resolved_count']
            faith = r['ragas']['faithfulness_score']
            lines.append(f"% {mode} {res} {faith:.2f}")
        
        return "\n".join(lines)
    
    def export_all(self, output_dir: Path):
        """Export all LaTeX files."""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Variables
        vars_file = output_dir / f'ablation_vars_{self.timestamp}.tex'
        with open(vars_file, 'w') as f:
            f.write(self.generate_vars_tex())
        print(f"Variables: {vars_file}")
        
        # Table
        table_file = output_dir / f'ablation_table_{self.timestamp}.tex'
        with open(table_file, 'w') as f:
            f.write(self.generate_table_tex())
        print(f"Table: {table_file}")
        
        # Appendix
        appendix_file = output_dir / f'ablation_appendix_{self.timestamp}.tex'
        with open(appendix_file, 'w') as f:
            f.write(self.generate_appendix_tex())
        print(f"Appendix: {appendix_file}")
        
        # Data for plots
        data_file = output_dir / f'ablation_data_{self.timestamp}.tex'
        with open(data_file, 'w') as f:
            f.write(self.generate_pgfplots_data())
        print(f"Plot data: {data_file}")
        
        return {
            'vars': vars_file,
            'table': table_file,
            'appendix': appendix_file,
            'data': data_file
        }


def main():
    """CLI for LaTeX export."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Export ablation results to LaTeX')
    parser.add_argument('json_file', type=Path, help='Input JSON results file')
    parser.add_argument('-o', '--output', type=Path, default=Path('data/analysis/latex'),
                        help='Output directory')
    
    args = parser.parse_args()
    
    if not args.json_file.exists():
        print(f"Error: {args.json_file} not found")
        return 1
    
    exporter = LaTeXExporter(args.json_file)
    exporter.export_all(args.output)
    
    print("\nLaTeX export complete!")
    return 0


if __name__ == '__main__':
    exit(main())