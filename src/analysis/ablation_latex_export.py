# -*- coding: utf-8 -*-
"""
LaTeX exporter for ablation study results.

Generates:
1. ablation_table.tex - Main results table
2. ablation_vars.tex - \\newcommand variables for inline citations
3. ablation_appendix.tex - Detailed I/O per query (detailed mode only)
4. ablation_data.tex - Data for pgfplots figures

Usage:
    from src.analysis.ablation_latex_export import LaTeXExporter
    exporter = LaTeXExporter(json_path, is_detailed=True)
    exporter.export_all(output_dir)
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional


def escape_latex(text: str) -> str:
    """Escape special LaTeX characters."""
    if not text:
        return ""
    replacements = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\textasciicircum{}',
        '\\': r'\textbackslash{}',
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text


def truncate_text(text: str, max_len: int = 80) -> str:
    """Truncate text for display."""
    if len(text) <= max_len:
        return text
    return text[:max_len-3] + "..."


class LaTeXExporter:
    """Export ablation results to LaTeX format."""
    
    def __init__(self, results_json: Path, is_detailed: bool = False):
        """
        Load results from JSON file.
        
        Args:
            results_json: Path to JSON results file
            is_detailed: Whether this is a detailed run (6 queries with full data)
        """
        with open(results_json) as f:
            self.results = json.load(f)
        
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Group by query
        self.by_query = {}
        for r in self.results:
            q = r['query']
            if q not in self.by_query:
                self.by_query[q] = {}
            self.by_query[q][r['mode']] = r
        
        # Group by mode
        self.by_mode = {'semantic': [], 'graph': [], 'dual': []}
        for r in self.results:
            self.by_mode[r['mode']].append(r)
        
        # Detect detailed mode from data or explicit flag
        self.is_detailed = is_detailed or len(self.by_query) <= 10
        self.has_chunks = any('chunks_detail' in r for r in self.results)
        self.has_answer = any(r.get('answer_text', '') for r in self.results)
    
    def compute_aggregates(self) -> Dict[str, Any]:
        """Compute aggregate statistics for variables."""
        agg = {}
        
        for mode in ['semantic', 'graph', 'dual']:
            results = self.by_mode[mode]
            if not results:
                continue
            
            # Faithfulness
            faith_scores = [r['ragas']['faithfulness_score'] for r in results]
            agg[f'faith_{mode}_mean'] = sum(faith_scores) / len(faith_scores)
            agg[f'faith_{mode}_max'] = max(faith_scores)
            agg[f'faith_{mode}_min'] = min(faith_scores)
            
            # Relevancy
            rel_scores = [r['ragas']['relevancy_score'] for r in results]
            agg[f'rel_{mode}_mean'] = sum(rel_scores) / len(rel_scores)
            
            # Resolution
            res_counts = [r['entity_resolution']['resolved_count'] for r in results]
            agg[f'res_{mode}_total'] = sum(res_counts)
            
            # Chunks by source
            s_total = sum(r['retrieval']['chunks_by_source'].get('semantic', 0) for r in results)
            r_total = sum(r['retrieval']['chunks_by_source'].get('graph_provenance', 0) for r in results)
            e_total = sum(r['retrieval']['chunks_by_source'].get('graph_entity', 0) for r in results)
            agg[f'chunks_{mode}_s'] = s_total
            agg[f'chunks_{mode}_r'] = r_total
            agg[f'chunks_{mode}_e'] = e_total
        
        # Winners by query
        winners = {'semantic': 0, 'graph': 0, 'dual': 0, 'tie': 0}
        for query, modes in self.by_query.items():
            scores = {m: modes[m]['ragas']['faithfulness_score'] for m in modes}
            max_score = max(scores.values())
            if max_score == 0:
                continue
            winner_modes = [m for m, s in scores.items() if s == max_score]
            if len(winner_modes) == 1:
                winners[winner_modes[0]] += 1
            else:
                winners['tie'] += 1
        
        agg['winners'] = winners
        agg['n_queries'] = len(self.by_query)
        agg['n_tests'] = len(self.results)
        
        return agg
    
    def generate_vars_tex(self) -> str:
        """Generate \\newcommand variables for inline citations."""
        agg = self.compute_aggregates()
        
        lines = [
            "% Auto-generated by ablation_latex_export.py",
            f"% Generated: {datetime.now().isoformat()}",
            "%",
            "% Metric definitions: See Appendix \\ref{app:metrics} (metrics_glossary.tex)",
            "% - Faithfulness: Section \\ref{sec:metric-faithfulness}",
            "% - Relevancy: Section \\ref{sec:metric-relevancy}",
            "% - Resolution Rate: Section \\ref{sec:metric-resolution-rate}",
            "% - Entity Coverage: Section \\ref{sec:metric-entity-coverage}",
            "%",
            "",
            "% === AGGREGATE STATISTICS ===",
            f"\\newcommand{{\\nQueries}}{{{agg['n_queries']}}}",
            f"\\newcommand{{\\nTests}}{{{agg['n_tests']}}}",
            "",
            "% === FAITHFULNESS (\\ref{sec:metric-faithfulness}) ===",
        ]
        
        for mode in ['semantic', 'graph', 'dual']:
            m = mode[0].upper()  # S, G, D
            lines.append(f"\\newcommand{{\\faith{m}Mean}}{{{agg.get(f'faith_{mode}_mean', 0):.2f}}}")
            lines.append(f"\\newcommand{{\\faith{m}Max}}{{{agg.get(f'faith_{mode}_max', 0):.2f}}}")
            lines.append(f"\\newcommand{{\\faith{m}Min}}{{{agg.get(f'faith_{mode}_min', 0):.2f}}}")
        
        lines.extend([
            "",
            "% === RELEVANCY (\\ref{sec:metric-relevancy}) ===",
        ])
        
        for mode in ['semantic', 'graph', 'dual']:
            m = mode[0].upper()
            lines.append(f"\\newcommand{{\\rel{m}Mean}}{{{agg.get(f'rel_{mode}_mean', 0):.2f}}}")
        
        lines.extend([
            "",
            "% === WINNERS (\\ref{sec:metric-winner}) ===",
            f"\\newcommand{{\\winsSemantic}}{{{agg['winners']['semantic']}}}",
            f"\\newcommand{{\\winsGraph}}{{{agg['winners']['graph']}}}",
            f"\\newcommand{{\\winsDual}}{{{agg['winners']['dual']}}}",
            f"\\newcommand{{\\winsTie}}{{{agg['winners']['tie']}}}",
            "",
            "% === PER-QUERY VARIABLES ===",
        ])
        
        # Per-query faithfulness
        for i, (query, modes) in enumerate(self.by_query.items(), 1):
            for mode in ['semantic', 'graph', 'dual']:
                if mode in modes:
                    m = mode[0].upper()
                    faith = modes[mode]['ragas']['faithfulness_score']
                    lines.append(f"\\newcommand{{\\faithQ{i}{m}}}{{{faith:.2f}}}")
        
        return "\n".join(lines)
    
    def generate_table_tex(self) -> str:
        """Generate the main results table."""
        lines = [
            "% Auto-generated ablation results table",
            "\\begin{table}[htbp]",
            "\\centering",
            "\\caption{Ablation Results Across Retrieval Modes}",
            "\\label{tab:ablation_results}",
            "\\resizebox{\\linewidth}{!}{%",
            "\\begin{tabular}{clccccccccc}",
            "\\toprule",
            "\\# & Query & Mode & Faith. & Relev. & Res. & Subgraph & S/R/E & Sim. & E.Cov & P/R \\\\",
            "\\midrule",
        ]
        
        row_num = 1
        for query, modes in self.by_query.items():
            q_escaped = escape_latex(truncate_text(query, 40))
            
            for i, mode in enumerate(['semantic', 'graph', 'dual']):
                if mode not in modes:
                    continue
                
                r = modes[mode]
                
                # Find best faithfulness for this query
                all_faith = [modes[m]['ragas']['faithfulness_score'] for m in modes]
                max_faith = max(all_faith)
                is_best = r['ragas']['faithfulness_score'] == max_faith and max_faith > 0
                
                # Format values
                faith = r['ragas']['faithfulness_score']
                faith_str = f"\\textbf{{{faith:.2f}}}" if is_best else f"{faith:.2f}"
                relev = r['ragas']['relevancy_score']
                res_count = r['entity_resolution']['resolved_count']
                
                # Subgraph
                sg_ent = r['graph_utilization']['entities_in_subgraph']
                sg_rel = r['graph_utilization']['relations_in_subgraph']
                subgraph = f"{sg_ent}/{sg_rel}"
                
                # Chunks by source
                src = r['retrieval']['chunks_by_source']
                s = src.get('semantic', 0)
                rel_c = src.get('graph_provenance', 0)
                e = src.get('graph_entity', 0)
                sre = f"{s}/{rel_c}/{e}"
                
                # Similarity
                sim = r['retrieval'].get('avg_query_similarity', 0)
                
                # Coverage
                e_cov = r['coverage'].get('entity_coverage_rate', 0) * 100
                
                # Source diversity
                src_div = r['retrieval'].get('source_diversity', {})
                p_count = src_div.get('paper', 0)
                r_count = src_div.get('regulation', 0)
                pr = f"{p_count}/{r_count}"
                
                # Row content
                if i == 0:
                    lines.append(f"{row_num} & {q_escaped} & {mode} & {faith_str} & {relev:.2f} & {res_count} & {subgraph} & {sre} & {sim:.2f} & {e_cov:.0f}\\% & {pr} \\\\")
                else:
                    lines.append(f" & & {mode} & {faith_str} & {relev:.2f} & {res_count} & {subgraph} & {sre} & {sim:.2f} & {e_cov:.0f}\\% & {pr} \\\\")
            
            lines.append("\\midrule")
            row_num += 1
        
        # Remove last midrule and add bottomrule
        lines[-1] = "\\bottomrule"
        
        lines.extend([
            "\\end{tabular}}",
            "\\begin{minipage}{\\linewidth}",
            "\\vspace{2mm}",
            "\\footnotesize\\textit{Note:} "
            "Faith.\\ = Faithfulness (\\S\\ref{sec:metric-faithfulness}); "
            "Relev.\\ = Relevancy (\\S\\ref{sec:metric-relevancy}); "
            "Res.\\ = entities resolved (\\S\\ref{sec:metric-resolution-rate}); "
            "Subgraph = nodes/relations (\\S\\ref{sec:metric-subgraph}); "
            "S/R/E = chunks by source (\\S\\ref{sec:metric-sre}); "
            "Sim.\\ = avg query-chunk similarity (\\S\\ref{sec:metric-similarity}); "
            "E.Cov = entity coverage (\\S\\ref{sec:metric-entity-coverage}); "
            "P/R = paper/regulation sources (\\S\\ref{sec:metric-source-diversity}). "
            "\\textbf{Bold} = best per query.",
            "\\end{minipage}",
            "\\end{table}",
        ])
        
        return "\n".join(lines)
    
    def generate_appendix_tex(self) -> str:
        """Generate detailed I/O appendix for each query."""
        
        # For non-detailed runs, generate a summary reference
        if not self.is_detailed:
            return self._generate_summary_appendix()
        
        lines = [
            "% Auto-generated detailed ablation appendix",
            "% For detailed mode only - includes full answers and retrieved chunks",
            "\\chapter{Detailed Query Analysis}",
            "\\label{app:detailed_queries}",
            "",
        ]
        
        for i, (query, modes) in enumerate(self.by_query.items(), 1):
            q_escaped = escape_latex(query)
            
            # Get query metadata from first result
            first_result = list(modes.values())[0]
            category = first_result.get('category', 'unknown')
            subcategory = first_result.get('subcategory', '')
            
            lines.extend([
                f"\\section{{Query {i}: {q_escaped}}}",
                f"\\label{{sec:q{i}}}",
                "",
                f"\\textbf{{Category:}} {escape_latex(category)}" + (f" ({escape_latex(subcategory)})" if subcategory else ""),
                "",
            ])
            
            # SECTION 1: Metrics comparison table
            lines.extend([
                "\\subsection*{Metrics Comparison}",
                "\\begin{table}[htbp]",
                "\\centering",
                "\\caption{Metrics for Query " + str(i) + "}",
                "\\begin{tabular}{lccc}",
                "\\toprule",
                "Metric & Semantic & Graph & Dual \\\\",
                "\\midrule",
            ])
            
            # Metrics rows
            metrics = [
                ('Faithfulness', lambda r: f"{r['ragas']['faithfulness_score']:.2f}"),
                ('Relevancy', lambda r: f"{r['ragas']['relevancy_score']:.2f}"),
                ('Entities Resolved', lambda r: str(r['entity_resolution']['resolved_count'])),
                ('Subgraph Nodes', lambda r: str(r['graph_utilization']['entities_in_subgraph'])),
                ('Subgraph Relations', lambda r: str(r['graph_utilization']['relations_in_subgraph'])),
                ('Total Chunks', lambda r: str(r['retrieval']['total_chunks'])),
                ('Avg Similarity', lambda r: f"{r['retrieval'].get('avg_query_similarity', 0):.2f}"),
                ('Entity Coverage', lambda r: f"{r['coverage'].get('entity_coverage_rate', 0)*100:.0f}\\%"),
            ]
            
            for metric_name, metric_fn in metrics:
                vals = []
                for mode in ['semantic', 'graph', 'dual']:
                    if mode in modes:
                        vals.append(metric_fn(modes[mode]))
                    else:
                        vals.append("---")
                lines.append(f"{metric_name} & {vals[0]} & {vals[1]} & {vals[2]} \\\\")
            
            lines.extend([
                "\\bottomrule",
                "\\end{tabular}",
                "\\end{table}",
                "",
            ])
            
            # SECTION 2: Full answers (only if available)
            if self.has_answer:
                lines.append("\\subsection*{Generated Answers}")
                
                for mode in ['semantic', 'graph', 'dual']:
                    if mode not in modes:
                        continue
                    
                    r = modes[mode]
                    answer = r.get('answer_text', '')
                    
                    if not answer:
                        answer = "(No answer recorded)"
                    
                    answer_escaped = escape_latex(answer)
                    faith = r['ragas']['faithfulness_score']
                    
                    lines.extend([
                        f"\\subsubsection*{{{mode.capitalize()} Mode (Faithfulness: {faith:.2f})}}",
                        "\\begin{tcolorbox}[colback=gray!5,colframe=gray!50,boxrule=0.5pt]",
                        f"\\small {answer_escaped}",
                        "\\end{tcolorbox}",
                        "",
                    ])
            
            # SECTION 3: Cited chunks table (only if detailed data available)
            if self.has_chunks:
                # Use semantic mode as reference (or first available)
                ref_mode = 'semantic' if 'semantic' in modes else list(modes.keys())[0]
                ref_result = modes[ref_mode]
                chunks = ref_result.get('chunks_detail', [])
                cited = ref_result.get('cited_chunks', [])
                
                if chunks:
                    lines.extend([
                        "\\subsection*{Retrieved Chunks (Semantic Mode)}",
                        "\\begin{longtable}{clp{7cm}cc}",
                        "\\toprule",
                        "\\# & Doc ID & Text (excerpt) & Score & Cited \\\\",
                        "\\midrule",
                        "\\endhead",
                    ])
                    
                    for c in chunks[:10]:  # Top 10
                        cited_mark = "$\\checkmark$" if c.get('cited', False) or c['index'] in cited else ""
                        text_excerpt = escape_latex(truncate_text(c['text'], 150))
                        doc_id = escape_latex(truncate_text(c['doc_id'], 20))
                        score = c.get('score', 0)
                        lines.append(
                            f"{c['index']} & {doc_id} & {text_excerpt} & {score:.2f} & {cited_mark} \\\\"
                        )
                    
                    lines.extend([
                        "\\bottomrule",
                        "\\end{longtable}",
                        "",
                    ])
            
            # SECTION 4: Relations table (only if detailed data available)
            if self.has_chunks:
                ref_mode = 'graph' if 'graph' in modes else list(modes.keys())[0]
                ref_result = modes[ref_mode]
                relations = ref_result.get('relations_detail', [])
                
                if relations:
                    lines.extend([
                        "\\subsection*{Subgraph Relations (Graph Mode, top 10)}",
                        "\\begin{tabular}{lll}",
                        "\\toprule",
                        "Source & Predicate & Target \\\\",
                        "\\midrule",
                    ])
                    
                    for rel in relations[:10]:
                        source = escape_latex(truncate_text(rel['source'], 25))
                        predicate = escape_latex(rel['predicate'])
                        target = escape_latex(truncate_text(rel['target'], 25))
                        lines.append(f"{source} & {predicate} & {target} \\\\")
                    
                    lines.extend([
                        "\\bottomrule",
                        "\\end{tabular}",
                        "",
                    ])
            
            lines.append("\\clearpage")
            lines.append("")
        
        return "\n".join(lines)
    
    def _generate_summary_appendix(self) -> str:
        """Generate a brief appendix for full runs (reference to main table)."""
        lines = [
            "% Auto-generated appendix for full ablation study",
            "\\chapter{Complete Ablation Results}",
            "\\label{app:full_results}",
            "",
            "This appendix contains the complete results for all 30 queries across 3 modes.",
            "For detailed qualitative analysis including full answer text and retrieved chunks,",
            "run the ablation study with the \\texttt{--detailed} flag.",
            "",
            "See Table~\\ref{tab:ablation_results} for the summary results.",
            "",
        ]
        
        # Add a compact per-query winner table
        lines.extend([
            "\\section{Per-Query Winners}",
            "\\begin{longtable}{clcccc}",
            "\\toprule",
            "\\# & Query & Category & Semantic & Graph & Dual \\\\",
            "\\midrule",
            "\\endhead",
        ])
        
        for i, (query, modes) in enumerate(self.by_query.items(), 1):
            q_escaped = escape_latex(truncate_text(query, 35))
            category = escape_latex(list(modes.values())[0].get('category', 'unknown'))
            
            scores = {}
            for mode in ['semantic', 'graph', 'dual']:
                if mode in modes:
                    scores[mode] = modes[mode]['ragas']['faithfulness_score']
                else:
                    scores[mode] = 0
            
            max_score = max(scores.values())
            
            def fmt_score(mode):
                s = scores[mode]
                if s == max_score and s > 0:
                    return f"\\textbf{{{s:.2f}}}"
                return f"{s:.2f}"
            
            lines.append(
                f"{i} & {q_escaped} & {category} & {fmt_score('semantic')} & {fmt_score('graph')} & {fmt_score('dual')} \\\\"
            )
        
        lines.extend([
            "\\bottomrule",
            "\\end{longtable}",
        ])
        
        return "\n".join(lines)
    
    def generate_pgfplots_data(self) -> str:
        """Generate data file for pgfplots figures."""
        lines = [
            "% Data for pgfplots - faithfulness by mode and category",
            "% Generated: " + datetime.now().isoformat(),
            "",
        ]
        
        # Group by category
        by_category = {}
        for query, modes in self.by_query.items():
            cat = list(modes.values())[0].get('category', 'unknown')
            if cat not in by_category:
                by_category[cat] = {'semantic': [], 'graph': [], 'dual': []}
            for mode in ['semantic', 'graph', 'dual']:
                if mode in modes:
                    by_category[cat][mode].append(modes[mode]['ragas']['faithfulness_score'])
        
        # === BAR CHART DATA (proper pgfplots format) ===
        lines.append("% === BAR CHART DATA: Faithfulness by Category ===")
        lines.append("% Usage: \\pgfplotstableread{\\categorytable}")
        lines.append("\\pgfplotstableread[col sep=space]{")
        lines.append("category semantic graph dual")
        
        for cat, mode_scores in sorted(by_category.items()):
            s_avg = sum(mode_scores['semantic']) / len(mode_scores['semantic']) if mode_scores['semantic'] else 0
            g_avg = sum(mode_scores['graph']) / len(mode_scores['graph']) if mode_scores['graph'] else 0
            d_avg = sum(mode_scores['dual']) / len(mode_scores['dual']) if mode_scores['dual'] else 0
            cat_clean = cat.replace('_', '-')
            lines.append(f"{cat_clean} {s_avg:.3f} {g_avg:.3f} {d_avg:.3f}")
        
        lines.append("}\\categorytable")
        lines.append("")
        
        # === SCATTER PLOT DATA ===
        lines.append("% === SCATTER PLOT DATA: Resolution vs Faithfulness ===")
        lines.append("% Format: (resolution, faithfulness) per mode")
        lines.append("")
        
        for mode in ['semantic', 'graph', 'dual']:
            lines.append(f"% {mode.upper()} mode coordinates")
            lines.append(f"\\def\\scatter{mode.capitalize()}{{")
            coords = []
            for r in self.by_mode[mode]:
                res = r['entity_resolution']['resolved_count']
                faith = r['ragas']['faithfulness_score']
                coords.append(f"({res},{faith:.3f})")
            lines.append("  " + " ".join(coords))
            lines.append("}")
            lines.append("")
        
        # === MODE COMPARISON DATA ===
        lines.append("% === MODE COMPARISON: Overall averages ===")
        lines.append("\\pgfplotstableread[col sep=space]{")
        lines.append("mode faithfulness relevancy")
        
        for mode in ['semantic', 'graph', 'dual']:
            results = self.by_mode[mode]
            if results:
                faith_avg = sum(r['ragas']['faithfulness_score'] for r in results) / len(results)
                rel_avg = sum(r['ragas']['relevancy_score'] for r in results) / len(results)
                lines.append(f"{mode} {faith_avg:.3f} {rel_avg:.3f}")
        
        lines.append("}\\modetable")
        
        return "\n".join(lines)
    
    def export_all(self, output_dir: Path):
        """Export all LaTeX files."""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Variables
        vars_file = output_dir / f'ablation_vars_{self.timestamp}.tex'
        with open(vars_file, 'w') as f:
            f.write(self.generate_vars_tex())
        print(f"Variables: {vars_file}")
        
        # Table
        table_file = output_dir / f'ablation_table_{self.timestamp}.tex'
        with open(table_file, 'w') as f:
            f.write(self.generate_table_tex())
        print(f"Table: {table_file}")
        
        # Appendix
        appendix_file = output_dir / f'ablation_appendix_{self.timestamp}.tex'
        with open(appendix_file, 'w') as f:
            f.write(self.generate_appendix_tex())
        print(f"Appendix: {appendix_file}")
        
        # Data for plots
        data_file = output_dir / f'ablation_data_{self.timestamp}.tex'
        with open(data_file, 'w') as f:
            f.write(self.generate_pgfplots_data())
        print(f"Plot data: {data_file}")
        
        return {
            'vars': vars_file,
            'table': table_file,
            'appendix': appendix_file,
            'data': data_file
        }


def main():
    """CLI for LaTeX export."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Export ablation results to LaTeX')
    parser.add_argument('json_file', type=Path, help='Input JSON results file')
    parser.add_argument('-o', '--output', type=Path, default=Path('data/analysis/latex'),
                        help='Output directory')
    parser.add_argument('--detailed', action='store_true',
                        help='Force detailed mode (full appendix with answers/chunks)')
    
    args = parser.parse_args()
    
    if not args.json_file.exists():
        print(f"Error: {args.json_file} not found")
        return 1
    
    exporter = LaTeXExporter(args.json_file, is_detailed=args.detailed)
    exporter.export_all(args.output)
    
    print("\nLaTeX export complete!")
    return 0


if __name__ == '__main__':
    exit(main())