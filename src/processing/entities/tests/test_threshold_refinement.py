# -*- coding: utf-8 -*-
"""
Phase 1C Threshold Refinement - Sample candidate pairs for human review.

Reads candidate pairs generated by disambiguation_processor (--phase faiss),
samples from different similarity bands for human labeling.

Input:  candidate_pairs.jsonl (from --phase faiss)
Output: 
  - threshold_samples.json (samples per band for labeling)
  - threshold_review.txt (human-readable format)

Workflow:
  1. python -m src.processing.entities.disambiguation_processor --phase faiss
  2. python -m src.processing.entities.tests.test_threshold_refinement
  3. Label pairs in threshold_review.txt
  4. Update thresholds in extraction_config.py
  5. python -m src.processing.entities.disambiguation_processor --phase full
"""

import json
import logging
import argparse
import random
from pathlib import Path
from typing import List, Dict

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Paths
DATA_DIR = Path('data')
PAIRS_FILE = DATA_DIR / 'interim' / 'entities' / 'candidate_pairs.jsonl'
SAMPLES_FILE = DATA_DIR / 'interim' / 'entities' / 'threshold_samples.json'

# Similarity bands for threshold tuning
SIMILARITY_BANDS = [
    ('0.98+', 0.98, 1.01),
    ('0.95-0.98', 0.95, 0.98),
    ('0.90-0.95', 0.90, 0.95),
    ('0.85-0.90', 0.85, 0.90),
    ('0.80-0.85', 0.80, 0.85),
    ('0.75-0.80', 0.75, 0.80),
    ('0.70-0.75', 0.70, 0.75),
]


def analyze_similarity_distribution(pairs: List[Dict]) -> Dict:
    """Analyze similarity distribution of pairs."""
    if not pairs:
        return {'total_pairs': 0, 'bands': {}}
    
    sims = [p['similarity'] for p in pairs]
    
    # Count per band
    bands = {}
    for band_name, low, high in SIMILARITY_BANDS:
        count = sum(1 for s in sims if low <= s < high)
        bands[band_name] = count
    
    stats = {
        'total_pairs': len(pairs),
        'min_similarity': min(sims),
        'max_similarity': max(sims),
        'mean_similarity': sum(sims) / len(sims),
        'bands': bands,
    }
    
    return stats


def sample_pairs_for_tuning(pairs: List[Dict], samples_per_band: int = 15,
                            seed: int = 42) -> Dict[str, List[Dict]]:
    """
    Sample pairs from each similarity band for human review.
    
    Returns dict of band -> sample pairs for labeling.
    """
    random.seed(seed)
    
    # Group by band
    band_pairs = {band_name: [] for band_name, _, _ in SIMILARITY_BANDS}
    
    for pair in pairs:
        sim = pair['similarity']
        for band_name, low, high in SIMILARITY_BANDS:
            if low <= sim < high:
                band_pairs[band_name].append(pair)
                break
    
    # Sample from each band
    samples = {}
    for band_name in band_pairs:
        band_list = band_pairs[band_name]
        n_sample = min(samples_per_band, len(band_list))
        if n_sample > 0:
            samples[band_name] = random.sample(band_list, n_sample)
        else:
            samples[band_name] = []
    
    return samples


def format_samples_for_review(samples: Dict[str, List[Dict]]) -> str:
    """Format samples as human-readable text for labeling."""
    lines = []
    lines.append("="*70)
    lines.append("THRESHOLD TUNING - Label each pair: SAME / DIFF / UNSURE")
    lines.append("="*70)
    lines.append("")
    lines.append("Instructions:")
    lines.append("  SAME  = These refer to the same real-world entity")
    lines.append("  DIFF  = These are different entities")
    lines.append("  UNSURE = Cannot determine without more context")
    lines.append("")
    lines.append("Goal: Find thresholds where:")
    lines.append("  - auto_merge: lowest band where nearly ALL are SAME")
    lines.append("  - auto_reject: highest band where nearly ALL are DIFF")
    lines.append("  - uncertain band in between â†’ send to LLM")
    
    for band_name, _, _ in SIMILARITY_BANDS:
        band_samples = samples.get(band_name, [])
        if not band_samples:
            continue
            
        lines.append(f"\n{'='*70}")
        lines.append(f"BAND: {band_name} ({len(band_samples)} samples)")
        lines.append("="*70)
        
        for i, pair in enumerate(band_samples, 1):
            lines.append(f"\n[{band_name}#{i}] sim={pair['similarity']:.4f}")
            lines.append(f"  A: {pair['entity1_name']} [{pair['entity1_type']}]")
            lines.append(f"  B: {pair['entity2_name']} [{pair['entity2_type']}]")
            lines.append(f"  Label: _______ (SAME / DIFF / UNSURE)")
    
    lines.append("\n" + "="*70)
    lines.append("SUMMARY - Fill in after labeling:")
    lines.append("="*70)
    lines.append("")
    for band_name, _, _ in SIMILARITY_BANDS:
        lines.append(f"  {band_name}: SAME=___ DIFF=___ UNSURE=___")
    lines.append("")
    lines.append("Recommended thresholds:")
    lines.append("  auto_merge_threshold:  ____")
    lines.append("  auto_reject_threshold: ____")
    lines.append("")
    lines.append("="*70)
    lines.append("END OF SAMPLES")
    lines.append("="*70)
    
    return "\n".join(lines)


def load_pairs(filepath: Path) -> List[Dict]:
    """Load candidate pairs from JSONL."""
    pairs = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                pairs.append(json.loads(line))
    logger.info(f"Loaded {len(pairs)} pairs from {filepath}")
    return pairs


def main():
    parser = argparse.ArgumentParser(
        description='Sample candidate pairs for threshold tuning',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Workflow:
  1. Run: python -m src.processing.entities.disambiguation_processor --phase faiss
  2. Run: python -m src.processing.entities.tests.test_threshold_refinement
  3. Open threshold_review.txt and label pairs as SAME/DIFF/UNSURE
  4. Count results per band and determine thresholds
  5. Update extraction_config.py with new thresholds
  6. Run: python -m src.processing.entities.disambiguation_processor --phase full
"""
    )
    parser.add_argument('--pairs', type=str, default=str(PAIRS_FILE),
                       help='Input candidate pairs JSONL')
    parser.add_argument('--samples', type=int, default=15,
                       help='Samples per band for tuning')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for sampling')
    args = parser.parse_args()
    
    pairs_path = Path(args.pairs)
    
    # Check if pairs file exists
    if not pairs_path.exists():
        logger.error(f"Pairs file not found: {pairs_path}")
        logger.error("Run disambiguation_processor first:")
        logger.error("  python -m src.processing.entities.disambiguation_processor --phase faiss")
        return
    
    # Load pairs
    pairs = load_pairs(pairs_path)
    
    if not pairs:
        logger.error("No pairs found in file")
        return
    
    # Analyze distribution
    stats = analyze_similarity_distribution(pairs)
    
    print("\n" + "="*50)
    print("SIMILARITY DISTRIBUTION")
    print("="*50)
    print(f"Total pairs:    {stats['total_pairs']:,}")
    if stats['total_pairs'] > 0:
        print(f"Min similarity: {stats['min_similarity']:.4f}")
        print(f"Max similarity: {stats['max_similarity']:.4f}")
        print(f"Mean:           {stats['mean_similarity']:.4f}")
        print("\nBands:")
        for band_name, _, _ in SIMILARITY_BANDS:
            count = stats['bands'].get(band_name, 0)
            pct = count / stats['total_pairs'] * 100 if stats['total_pairs'] > 0 else 0
            print(f"  {band_name}: {count:>6,} ({pct:>5.1f}%)")
    
    # Sample for tuning
    samples = sample_pairs_for_tuning(pairs, samples_per_band=args.samples, seed=args.seed)
    
    # Save samples as JSON
    SAMPLES_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(SAMPLES_FILE, 'w', encoding='utf-8') as f:
        # Clean samples for JSON (remove idx)
        samples_clean = {}
        for band, pairs_list in samples.items():
            samples_clean[band] = [
                {k: v for k, v in p.items() if not k.startswith('idx')}
                for p in pairs_list
            ]
        json.dump(samples_clean, f, ensure_ascii=False, indent=2)
    logger.info(f"Saved samples to {SAMPLES_FILE}")
    
    # Save human-readable format
    review_file = SAMPLES_FILE.parent / 'threshold_review.txt'
    review_text = format_samples_for_review(samples)
    with open(review_file, 'w', encoding='utf-8') as f:
        f.write(review_text)
    logger.info(f"Saved review file to {review_file}")
    
    # Print summary
    print("\n" + "="*50)
    print("OUTPUT FILES")
    print("="*50)
    print(f"All pairs:     {PAIRS_FILE}")
    print(f"Samples JSON:  {SAMPLES_FILE}")
    print(f"Review file:   {review_file}")
    print("\n" + "="*50)
    print("NEXT STEPS")
    print("="*50)
    print(f"1. Open {review_file}")
    print("2. Label each pair: SAME / DIFF / UNSURE")
    print("3. Count results per band")
    print("4. Determine thresholds:")
    print("   - auto_merge: lowest band where ~90%+ are SAME")
    print("   - auto_reject: highest band where ~90%+ are DIFF")
    print("5. Update ENTITY_DISAMBIGUATION_CONFIG in extraction_config.py")


if __name__ == '__main__':
    main()